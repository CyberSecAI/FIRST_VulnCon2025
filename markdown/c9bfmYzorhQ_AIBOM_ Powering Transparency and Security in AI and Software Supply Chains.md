# AIBOM_ Powering Transparency and Security in AI and Software Supply Chains

**Video URL:** [https://www.youtube.com/watch?v=c9bfmYzorhQ](https://www.youtube.com/watch?v=c9bfmYzorhQ)
**Video ID:** c9bfmYzorhQ

---

SUMMARY
Dimiter Raidman, CTO of Syitz Cab, discusses AI SBOMs (Software Bill of Materials), their importance, risks, and future implications.

IDEAS
* AI SBOMs are crucial for understanding and securing the AI supply chain.
* AI systems' complexity makes them vulnerable to various attacks.
* Data poisoning is a major risk, manipulating model results.
* Model inversion attacks can extract sensitive training data.
* Prompt injections can manipulate chatbots through social engineering.
* AI SBOMs provide transparency and enable faster patching.
* They help organizations adhere to regulations and manage risks.
* Model cards often lack structured data, hindering analysis.
* AI SBOM generators are under development to address this issue.
* Organizations should perform risk assessments on AI models.
* Collaboration with the AI SBOM tiger team is encouraged.
* AI SBOMs are essential for building secure and resilient AI systems.
* They help manage the risks associated with AI adoption.
* AI SBOMs enable organizations to understand their AI landscape.
* They facilitate better preparation for the future of AI.
* AI models lack clear versioning, making identification difficult.
* Model performance metrics are crucial for assessing bias and precision.
* Model licensing information and data set licensing must be understood.
* Model creators often don't share data sources, hindering analysis.
* Classification data helps identify sensitive information in data sets.
* AI SBOMs integrate with MLSecOps pipelines for enhanced security.
* Generating AI SBOMs for third-party models is currently challenging.
* Hugging Face API and dependency analysis can aid in AI SBOM generation.
* AI SBOMs enable continuous monitoring of AI systems.
* They support adherence to regulations by collecting evidence.
* Seven key use cases for AI SBOMs have been identified.
* Open-source AI SBOM generators are being developed.
* New frameworks from OWASP assist in AI risk assessment.
* Manipulating training data can have serious consequences.
* Data embedded in models can affect inference and decisions.

INSIGHTS
* AI SBOMs are essential for secure and transparent AI development.
* The complexity of AI systems necessitates robust security measures.
* Data integrity is paramount for reliable AI model operation.
* Collaboration and standardization are key for AI SBOM adoption.
* AI SBOMs empower organizations to manage AI risks effectively.
* They provide a foundation for building trust and compliance in AI.
* AI model versioning and licensing require greater clarity.
* AI risk assessment should consider both data and code vulnerabilities.
* Continuous monitoring and patching are crucial for AI security.
* AI SBOMs facilitate responsible AI development and deployment.

QUOTES
* "If I can't answer that question, I don't have an AI problem. I have a different type of problem which is governance, security, and compliance nightmare I'm going to experience." - Dimiter Raidman
* "And that's exactly why we need DCIS bonds, right? Because we need to know...a sophisticated adversary exploited a vulnerability." - Dimiter Raidman
* "That's the danger zone because if one of these supply chain components is compromised or it has a bug, right? A honest mistake of the open source maintainers." - Dimiter Raidman
* "So basically we're rushing all of this to the market. We're trying yeah it solves a big problem because on one hand it reduces our need for you know effort basically people working right now." - Dimiter Raidman
* "AISBOM stands for artificial intelligence bill of materials. is really enabler for AI building and development transparency and security." - Dimiter Raidman
* "So, how we going to know about that? Interesting. And this is where really AISBOM comes into power, right?" - Dimiter Raidman
* "There is no generator today which can we can point at something right and say hey I want a AI sbomb to be created for me." - Dimiter Raidman
* "The unfortunate news...is that every model has its model card and guess what it's it's basically a free text." - Dimiter Raidman
* "Helen is working on the solution and she built these days the AIS boom generator that she she planning to releases in open source." - Dimiter Raidman
* "So you can scan QR code. If you don't like to scan QR codes, just come to me. I'll give you the link directly for Luma registration." - Dimiter Raidman
* "And eventually that's our call to action right uh use sbombs AIS bombs as your foundation generate the AI sbombs for thirdparty models perform risk assessment." - Dimiter Raidman
* "There's attack vectors that are, you know, related to data and then there's other ones that are more related to code." - Jodi Wadwa
* "And it would be nice and if I I don't know how they're being differentiated, but I think that's important. I see them always looped together." - Jodi Wadwa
* "So it's really tied together, right? because manipulating the data can manipulate or result in very serious consequences in the operation of the model." - Dimiter Raidman

HABITS
* Leverages open-source tools and frameworks for AI development.
* Analyzes model performance metrics to assess bias and precision.
* Investigates the provenance of open-source components and models.
* Considers licensing information for both models and data sets.
* Engages with the AI SBOM community and contributes to its development.
* Attends industry events like RSA to stay informed about AI security.
* Shares knowledge and resources with the community through GitHub.
* Continuously monitors AI systems for integrity and anomalies.
* Performs risk assessments on AI models before deployment.
* Advocates for the use of AI SBOMs for enhanced security.
* Collaborates with CISA and other organizations on AI security standards.
* Encourages due diligence when selecting open-source AI models.
* Prioritizes data sanitization and proper data handling practices.
* Uses hashes of commit IDs to precisely identify model versions.
* Adapts to the evolving landscape of AI security and risk management.

FACTS
* AI models can make incorrect market recommendations, causing financial losses.
* AI systems have high complexity due to layers, data models, and infrastructure.
* Agentic AI increases the complexity of AI systems significantly.
* AI models can be manipulated through prompt injection and social engineering.
* Model inversion attacks can extract sensitive data used for training.
* Denial-of-service attacks can take down AI models and systems.
* Data poisoning is a significant risk in AI model development.
* Model cards often contain unstructured free text, making analysis difficult.
* SPDX and CycloneDX standards support AI SBOMs.
* Nvidia patched a high-severity vulnerability affecting its hardware.
* ZenML had a vulnerability in its API that allowed unauthorized access.
* There are no automated generators for AI SBOMs currently available.
* Hugging Face is a popular platform for machine learning and AI.
* OWASP provides frameworks for AI risk assessment.
* CISA is working on defining AI SBOM standards and use cases.

REFERENCES
* Syitz Cab
* CISA
* SAP
* Manifest Cyber
* Acme Investment Portfolio Trading
* Hugging Face
* Nvidia
* Jetson Linux
* NVD (National Vulnerability Database)
* ZenML
* AISBOM (AI Software Bill of Materials)
* SBOM (Software Bill of Materials)
* CycloneDX
* SPDX
* Rakutin 7B
* PyTorch
* Transformers
* OWASP (Open Worldwide Application Security Project)
* GitHub
* RSA Conference
* AI SBOM Tiger Team
* Luma

ONE-SENTENCE TAKEAWAY
Generate and utilize AI SBOMs to enhance AI system security, transparency, and risk management.

RECOMMENDATIONS
* Implement AI SBOMs to gain visibility into your AI supply chain.
* Perform regular risk assessments on AI models and data sets.
* Prioritize data security and sanitization to prevent data poisoning.
* Use strong access controls and authentication for AI pipelines.
* Monitor AI model performance for anomalies and unexpected behavior.
* Stay informed about emerging AI security threats and vulnerabilities.
* Collaborate with industry groups and contribute to AI SBOM standards.
* Educate developers on secure AI development practices.
* Consider model licensing and data set licensing implications.
* Use version control and hashes to track AI model changes.
* Integrate AI SBOMs into your existing security workflows.
* Leverage OWASP frameworks for AI risk assessment.
* Engage with the AI SBOM community for support and resources.
* Advocate for greater transparency in AI model development.
* Prepare for the evolving regulatory landscape around AI.
