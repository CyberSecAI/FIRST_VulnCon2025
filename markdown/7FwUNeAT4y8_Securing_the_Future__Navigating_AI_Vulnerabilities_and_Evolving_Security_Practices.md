# Securing the Future: Navigating AI Vulnerabilities and Evolving Security Practices

**Video URL:** [https://www.youtube.com/watch?v=7FwUNeAT4y8](https://www.youtube.com/watch?v=7FwUNeAT4y8)
**Video ID:** 7FwUNeAT4y8

---

**SUMMARY**
Lisa Bradley and Sarah Evans discuss AI's growing role in software, its vulnerabilities, and evolving security practices, emphasizing data protection, supply chain security, and universal attestation frameworks.

**IDEAS:**
* AI's integration into software enhances product capabilities, generating code snippets, identifying bugs, and supporting coding efforts, improving software quality through automation testing.
* Understanding risks in machine learning models and large language models is crucial, requiring threat modeling and leveraging industry resources like OASP.
* Protecting data inputted into AI systems is essential to prevent proprietary data or IP leakage, extending security vulnerabilities related to AI.
* Security hygiene principles must extend to AI-specific components within applications, including training models and model responses, ensuring comprehensive protection.
* AI-related vulnerabilities exist in all stages of the AI lifecycle and supply chain, including data, models, and deployment, requiring constant vigilance.
* Poor system architecture and operational hygiene provide rich attack surfaces for threat actors, emphasizing the need for robust security practices.
* Poorly integrated supply chain security leads to upstream vulnerabilities in AI technology, necessitating strong security practices along the supply chain.
* Data management and classification are crucial to prevent IP leakage and infiltration into data sets fed into AI systems, ensuring data integrity.
* Identifying the stage, goals, and attack types is essential for classifying AI vulnerabilities, requiring a new approach to vulnerability management.
* Data poisoning, a type of cyber attack, manipulates data used to develop AI models, leading to bad data or malicious outputs for end-users.
* AI-related supply chain focuses on third-party data sets, pre-trained models, and plugins, adding weaknesses and requiring secure supplier hygiene practices.
* Extending current business practices, controls, and compliance is necessary to include AI components with risks and threats in the supply chain.
* Capturing metadata, increasing integrity, organizing metadata, and sharing with others are key recommendations for AI supply chain security.
* The Cyber Resiliency Act highlights the need to report known exploitable vulnerabilities and maintain patches, extending to AI vulnerabilities.
* Converged enterprise security operations, including data ops and ML/LLM ops, are essential for building, deploying, and responding to AI incidents.
* A universal attestation framework is needed to identify and respond to AI vulnerabilities, requiring automated, integrated, and easy-to-adopt solutions.
* Establishing integrity, reporting on that integrity, and verifying that integrity are crucial for AI applications and components, building on existing mechanisms.
* AI applications and components require deeper and more proactive thinking, extending current ideas to address broader needs in vulnerability remediation.
* Collaboration and communication are essential to address AI vulnerabilities, bringing together diverse expertise and perspectives across the industry.
* Evolving compliance for products and vulnerability remediation requires proactive thinking about potential gaps and opportunities to close them effectively.
* Thinking about AI applications and how to respond to incidents will require bringing in different stakeholders to address different parts of the problem.
* Attesting to models and model cards with machine-readable ways to verify data processing is crucial for ensuring AI system integrity.
* Finding people in your enterprise or industry who know different parts of the AI supply chain is essential for comprehensive security.
* The industry needs a universal attestation framework to identify and respond to AI vulnerabilities effectively, ensuring product security.

**INSIGHTS:**
* AI's rapid integration necessitates a proactive, holistic security approach, extending beyond traditional methods to encompass data, models, and supply chains.
* Converged security operations, integrating diverse expertise, are crucial for effectively managing AI vulnerabilities and ensuring comprehensive protection across the enterprise.
* Universal attestation frameworks are essential for establishing trust and transparency in AI systems, enabling rapid identification and remediation of vulnerabilities.
* Data integrity is paramount in AI systems; poisoning can have far-reaching consequences, requiring robust validation and monitoring throughout the lifecycle.
* Supply chain security in AI demands rigorous assessment of third-party components, ensuring that all suppliers adhere to stringent security practices.
* Evolving regulatory landscapes, like the Cyber Resiliency Act, necessitate proactive adaptation of security practices to address AI-specific vulnerabilities.
* Collaboration and knowledge sharing across the industry are vital for developing effective strategies to mitigate AI risks and promote secure innovation.
* Machine-readable attestations are key to automating and scaling vulnerability management, enabling rapid response to emerging threats in AI systems.
* Addressing AI vulnerabilities requires a shift in mindset, recognizing that end-users may need to be informed about data-related issues.
* Viewing AI security through the lens of the "blind men and the elephant" highlights the need for diverse perspectives and unified understanding.
* Proactive identification of gaps in AI security practices is essential for mitigating risks and ensuring the responsible deployment of AI technologies.
* Extending existing security frameworks to incorporate AI-specific components is crucial for maintaining a robust and adaptable security posture.
* The convergence of hardware, software, and data attestations is necessary for creating a comprehensive and verifiable security ecosystem for AI.
* Establishing clear lines of communication and coordination among stakeholders is vital for effectively responding to AI-related incidents.

**QUOTES:**
* "I call my team Prada which we focus on product remediation and dependency assurance primarily focusing on product security." - Lisa Bradley
* "I do security innovation research. This means that I get to take my IT operations and security operations background." - Sarah Evans
* "AI tools can actually generate our code snippets, identify bugs, and really do a lot of the coding or support our coding efforts." - Lisa Bradley
* "We have to remember that we have to protect it in every aspect in every sense of the way." - Lisa Bradley
* "AI related vulnerabilities, they can actually be found in all stages of the AI life cycle and the supply chain." - Lisa Bradley
* "Poor system architecture and operational hygiene. So this will provide rich attack services to threat actors." - Lisa Bradley
* "Poorly integrated supply chain security will cause you know like an upstream vulnerability in the AI technology." - Lisa Bradley
* "You're only as secure as your weakest point within your system." - Lisa Bradley
* "We will need to start thinking about how do we articulate these components in a bill of materials." - Sarah Evans
* "There's a lot of opportunity for us to start proactively thinking about how we're going to need to extend our software vulnerability remediation." - Sarah Evans
* "Capture metadata, increase integrity, organize your metadata and share with others." - Sarah Evans
* "We need to start kind of being proactive in thinking forward around what maybe what are some gaps." - Sarah Evans
* "Finding the people in your enterprise, the people in your industry that may know a different part of the AI supply chain." - Sarah Evans
* "AI applications and components are going to really require us to think a little bit more deeply and proactively." - Sarah Evans
* "It's been really great to partner with you thinking about how things are going to evolve and how we work to really advance that story together." - Lisa Bradley

**HABITS:**
* Lisa focuses on product remediation and dependency assurance, ensuring product security and awareness of vulnerabilities in dependencies.
* Sarah leverages her IT and security operations background to inform security innovation research in the CTO's office.
* Lisa and Sarah both have experience teaching, demonstrating a commitment to continuous learning and knowledge sharing.
* Sarah earned a certificate in AI and ML to deepen her understanding of risks in machine learning models.
* Lisa and Sarah actively monitor industry resources like OASP to stay informed about emerging AI threats.
* Sarah emphasizes the importance of capturing, organizing, and sharing metadata for AI supply chain security.
* Lisa and Sarah proactively think about extending current business practices to include AI components with risks and threats.
* Sarah advocates for converged enterprise security operations, integrating data ops and ML/LLM ops.
* Lisa and Sarah emphasize the need for a universal attestation framework to identify and respond to AI vulnerabilities.
* Sarah encourages collaboration and communication across the industry to address AI vulnerabilities effectively.
* Lisa and Sarah proactively identify gaps in AI security practices to mitigate risks and ensure responsible AI deployment.
* Sarah emphasizes the importance of machine-readable attestations for automating and scaling vulnerability management.
* Lisa and Sarah promote a shift in mindset, recognizing the need to inform end-users about data-related vulnerabilities.
* Sarah encourages finding people in your enterprise or industry who know different parts of the AI supply chain.
* Lisa and Sarah work together to advance the story of AI security, combining their expertise and perspectives.

**FACTS:**
* AI is increasingly integrated into software, enhancing product capabilities and supporting coding efforts.
* OASP provides industry resources, including top 10 lists for machine learning and large language model threats.
* AI-related vulnerabilities can be found in all stages of the AI lifecycle and supply chain.
* Poor system architecture and operational hygiene provide rich attack surfaces for threat actors.
* Poorly integrated supply chain security can lead to upstream vulnerabilities in AI technology.
* Data poisoning is a type of cyber attack that manipulates data used to develop AI models.
* AI supply chain attacks can occur when an attack modifies or replaces a machine learning library or model.
* The Cyber Resiliency Act is a consumer compliance act out of the EU for devices with digital elements.
* The Cyber Resiliency Act requires reporting known exploitable vulnerabilities and maintaining patches.
* Google has done significant work in AI supply chain security, offering controls and recommendations.
* Converged enterprise security operations include data ops and ML/LLM ops.
* A universal attestation framework is needed to identify and respond to AI vulnerabilities.
* Machine-readable attestations are essential for automating and scaling vulnerability management.
* AI applications and components require deeper and more proactive security thinking.
* Collaboration and communication are essential for addressing AI vulnerabilities effectively.

**REFERENCES:**
* Dell Technologies (Lisa Bradley's employer)
* IBM (Lisa Bradley's former employer)
* Nvidia (Lisa Bradley's former employer)
* Jennisio (Lisa Bradley's undergraduate alma mater)
* NC State (Lisa Bradley's PhD alma mater)
* Office of the CTO (Sarah Evans' workplace)
* Missouri State University (Sarah Evans' MBA alma mater)
* Air Force (Sarah Evans' former employer)
* OASP (Open Worldwide Application Security Project)
* Google (Mentioned for their work in AI supply chain security)
* Cyber Resiliency Act (EU consumer compliance act)
* Vector databases (New types of databases)
* Rag architecture (Retrieval augmented generation)
* Knowledge graphs (Frameworks)
* DEO attestation (Compliance attestation)

**ONE-SENTENCE TAKEAWAY**
Securing AI's future requires proactive, collaborative strategies, integrating diverse expertise, and establishing universal attestation frameworks for vulnerability remediation.

**RECOMMENDATIONS:**
* Extend security hygiene principles to AI-specific components, including training models and model responses, ensuring comprehensive application protection.
* Implement robust data management and classification practices to prevent IP leakage and infiltration into data sets used in AI systems.
* Focus on identifying the stage, goals, and attack types to effectively classify AI vulnerabilities, requiring a new vulnerability management approach.
* Protect data and data models along the way, securing different components in the AI space, thinking about supply chain that way.
* Integrate third-party data sets, pre-trained models, and plugins securely, recognizing that AI supply chain weaknesses impact overall system security.
* Extend current business practices, controls, and compliance to include AI components with risks and threats in the supply chain effectively.
* Capture metadata, increase integrity, organize metadata, and share with others, following key recommendations for AI supply chain security proactively.
* Proactively think forward around potential gaps and opportunities to close them, evolving compliance for products and vulnerability remediation effectively.
* Bring in different stakeholders to address different parts of the problem, thinking about AI applications and how to respond to incidents.
* Attest to models and model cards with machine-readable ways to verify data processing, ensuring AI system integrity and transparency effectively.
* Find people in your enterprise or industry who know different parts of the AI supply chain, fostering collaboration and knowledge sharing.
* Establish integrity, report on that integrity, and verify that integrity, ensuring AI applications and components are secure and trustworthy.
* Think more deeply and proactively about AI applications and components, extending current ideas to address broader vulnerability remediation needs.
* Explore industry reference links to connect and explore other areas, finding people to share expertise with as they seek understanding.
* Develop a universal attestation framework to identify and respond to AI vulnerabilities effectively, ensuring product security and compliance.
