# Breaking the Bot_ GenAI Web App Attack Surface & Exploitation

**Video URL:** [https://www.youtube.com/watch?v=YM7QG80jGK4](https://www.youtube.com/watch?v=YM7QG80jGK4)
**Video ID:** YM7QG80jGK4

---

SUMMARY
Ken Smith, Director of Learning and Development at Ptorian, discusses GenAI threat modeling and the OWASP Top 10 for LLMs.

IDEAS
* Threat modeling with PASA helps understand business objectives and technical scope.
* Application decomposition involves analyzing user levels, entry points, and data handling.
* Threat analysis categorizes threats based on actor types, capabilities, and goals.
* Vulnerability analysis identifies potential weaknesses and uses frameworks like CVSS and OWASP.
* Attack path analysis combines elements to form attack scenarios for testing.
* Test cases define the approach for hands-on testing and inform risk assessment.
* Prompt injection manipulates model responses to alter behavior and bypass safety measures.
* Sensitive information disclosure exposes data like file systems, codebases, or system prompts.
* Supply chain issues arise from vulnerabilities in third-party components or models.
* Data and model poisoning involves manipulating training data to introduce backdoors or bias.
* Improper output handling fails to validate outputs, leading to XSS or code injection.
* Excessive agency allows LLMs to act beyond intended permissions, accessing sensitive data.
* System prompt leakage exposes the guardrails of the LLM, aiding prompt injection.
* Vector and embedding weaknesses involve vulnerabilities in how data is represented.
* Misinformation includes hallucinations by the LLM and over-reliance by users.
* Unbound consumption occurs when LLMs operate without constraints, causing denial of service.
* System prompt engineering methodologies guide the creation of robust system prompts.
* Chat templating and completion standards promote secure development practices.
* Prompt fuzzing and testing tools automate vulnerability discovery in LLMs.
* Content filters and sanitization validate inputs and outputs to prevent XSS and injection.
* Monitoring for traditional vulnerabilities addresses SQL injection and other common web flaws.
* Limiting permissions and agency adheres to least privilege and restricts LLM access.
* Supervisor LLMs oversee input and output of other LLMs to detect malicious behavior.
* Threat modeling and code reviews are crucial for assessing LLM security.
* Training resources like Gandalf, Prompt Airlines, and Portswigger Academy Labs offer hands-on practice.

INSIGHTS
* Effective threat modeling requires a wide scope, considering business, technical, and threat landscape.
* Prompt injection is a key vulnerability in LLMs, enabling various other attacks.
* Traditional web application vulnerabilities remain relevant in LLM applications.
* Supply chain and data poisoning pose significant risks to LLM integrity and security.
* Insufficient output handling can lead to severe consequences like XSS and code execution.
* Excessive agency and system prompt leakage undermine access control and security measures.
* Misinformation and unbound consumption highlight the importance of LLM limitations.
* Robust system prompt engineering and testing are crucial for secure LLM development.
* Content filtering, input validation, and least privilege are essential security practices.
* Supervisor LLMs offer a promising approach for enhancing LLM security.

QUOTES
* "I'm just here to draw with crayon on the wall." - Ken Smith
* "The wider we go the more accurate our model our threat model can be." - Ken Smith
* "It's way easier to cut content out that you don't need." - Ken Smith
* "At the end of the day the threat modeling and the risk and all of that comes down to cost." - Ken Smith
* "Don't trust the users." - Ken Smith
* "What's old is new again." - Ken Smith
* "We don't like to go into risk-informed penetration testing just throw at the wall and see what sticks." - Ken Smith
* "Jailbreaking attacks usually result in what we call the screenshot attacks." - Ken Smith
* "LLMs, GenAI in general, very, very good at predicting what comes next." - Ken Smith
* "Sometimes it is that easy." - Ken Smith
* "This is not actually social engineering. It's a computer." - Ken Smith
* "You get garbage in, you get garbage out." - Ken Smith
* "Read your stuff, verify your data." - Ken Smith
* "Please don't roll your own." - Ken Smith

HABITS
* Ken Smith teaches college courses and conducts workshops.
* Ken Smith emphasizes going wide in the initial steps of threat modeling.
* Ken Smith uses pasta (PASA) framework for threat modeling.
* Ken Smith recommends using CVSS and OWASP for vulnerability classification.
* Ken Smith advocates for combining multiple prompt injection techniques.
* Ken Smith emphasizes testing before big releases and as part of the development lifecycle.
* Ken Smith recommends using industry-standard chat templating and completion methods.
* Ken Smith suggests using a WAF and other traditional application security controls.
* Ken Smith advises adhering to the principle of least privilege for LLMs.
* Ken Smith recommends red teaming LLM applications to identify vulnerabilities.

FACTS
* Sokovia Accords aim to control superheroes in the Marvel Cinematic Universe.
* MITRE's Atlas matrix provides an attack framework for LLMs.
* Simon Willis coined the term "prompt injection".
* Prompt injection and jailbreaking are often used interchangeably but are distinct.
* LLMs are good at predicting what comes next based on data analysis.
* Hugging Face is a repository for pre-built models.
* LLMs on devices are becoming popular, especially in education.
* Amazon uses GenAI for creating review summaries.
* Lawyers have used ChatGPT and cited fake cases.
* An LLM falsely declared a man had killed his children.
* Unbound consumption can lead to denial of service and economic losses.
* Intense computing resources are necessary to run LLMs at scale.

REFERENCES
* PASA (Ptorian's threat modeling framework)
* Jarvis 2.0 (hypothetical application)
* Sokovia Accords
* MITRE's Atlas matrix
* Simon Willis's website and blog post on prompt injection
* 2001: A Space Odyssey (HAL)
* Roger Rabbit (shave and a haircut bit)
* CVE/CWE
* CVSS
* OWASP Top 10
* PTOS (Ptorian's intentionally vulnerable application)
* Llama
* Hugging Face
* Struts vulnerability (2017)
* Gandalf (LLM trainer)
* Whiz (LLM trainer)
* Prompt Airlines (LLM trainer)
* Portswigger Academy Labs
* LLM Guard
* Lera Guard
* Prompt Guard
* Metal Llama Guard

ONE-SENTENCE TAKEAWAY
Understand and mitigate LLM vulnerabilities through threat modeling, testing, and secure development practices.

RECOMMENDATIONS
* Use the PASA framework for comprehensive threat modeling of LLM applications.
* Employ OWASP Top 10 and CVSS for vulnerability analysis and prioritization.
* Combine various prompt injection techniques to thoroughly test LLM security.
* Vet data sources and models to mitigate supply chain and poisoning risks.
* Implement robust input and output validation to prevent common web vulnerabilities.
* Adhere to least privilege and limit LLM access to sensitive information.
* Use supervisor LLMs to monitor and control the behavior of other LLMs.
* Conduct regular red teaming and code reviews to assess LLM security posture.
* Leverage training resources like Gandalf and Prompt Airlines for hands-on practice.
* Implement rate limiting, timeouts, and throttling to prevent unbound consumption.
* Utilize content filters and sanitization to prevent malicious output execution.
* Monitor for traditional vulnerabilities like SQL injection and cross-site scripting.
* Use industry-standard chat templating and completion methods for secure development.
* Incorporate prompt fuzzing and testing tools into the development lifecycle.
* Stay updated on emerging LLM vulnerabilities and best practices for mitigation.
* Consider the ethical implications of LLM use and mitigate potential biases.
* Verify LLM outputs and avoid over-reliance on generated information.
