Kind: captions Language: en Morning everyone. How's the uh week Morning everyone. How's the uh week Morning everyone. How's the uh week going? Seen some good going? Seen some good going? Seen some good presentations. We're about halfway presentations. We're about halfway presentations. We're about halfway through. Well, my name is Kyle Kian um through. Well, my name is Kyle Kian um through. Well, my name is Kyle Kian um with the Rand Corporation. I'm joined by with the Rand Corporation. I'm joined by with the Rand Corporation. I'm joined by my partner here uh D Ferguson and Sasha my partner here uh D Ferguson and Sasha my partner here uh D Ferguson and Sasha Romanowski uh probably a well-known name Romanowski uh probably a well-known name Romanowski uh probably a well-known name to a lot of folks uh bowed out on us. to a lot of folks uh bowed out on us. to a lot of folks uh bowed out on us. So, he's he's not here, but uh this is a So, he's he's not here, but uh this is a So, he's he's not here, but uh this is a lot of the same work we're doing. We lot of the same work we're doing. We lot of the same work we're doing. We have a ongoing project looking at have a ongoing project looking at have a ongoing project looking at vulnerability ecosystem and the impact vulnerability ecosystem and the impact vulnerability ecosystem and the impact of AI. So we'd love to talk to any of of AI. So we'd love to talk to any of of AI. So we'd love to talk to any of you after the presentation or down the you after the presentation or down the you after the presentation or down the next couple weeks. Now without further next couple weeks. Now without further next couple weeks. Now without further ado, I will pass it off to my partner D. ado, I will pass it off to my partner D. ado, I will pass it off to my partner D. Good morning everyone. So I want to go Good morning everyone. So I want to go Good morning everyone. So I want to go over our brief agenda. Um we kind of over our brief agenda. Um we kind of over our brief agenda. Um we kind of divided our uh talk into two different divided our uh talk into two different divided our uh talk into two different parts. In part one we're looking at parts. In part one we're looking at parts. In part one we're looking at assigning AI model vulnerabilities. the assigning AI model vulnerabilities. the assigning AI model vulnerabilities. the current software vulnerability current software vulnerability current software vulnerability ecosystem, new vulnerabilities and ecosystem, new vulnerabilities and ecosystem, new vulnerabilities and classification challenges with AI, and classification challenges with AI, and classification challenges with AI, and then assigning AI model vulnerabilities then assigning AI model vulnerabilities then assigning AI model vulnerabilities and vulnerability disclosure. And then and vulnerability disclosure. And then and vulnerability disclosure. And then in part two, we'll be looking at the in part two, we'll be looking at the in part two, we'll be looking at the increasing vulnerabilities and AI's increasing vulnerabilities and AI's increasing vulnerabilities and AI's potential impact. So looking at AI and potential impact. So looking at AI and potential impact. So looking at AI and vulnerability discovery, AI augmented vulnerability discovery, AI augmented vulnerability discovery, AI augmented exploitation and defense, and then exploitation and defense, and then exploitation and defense, and then lastly, adapting the vulnerability lastly, adapting the vulnerability lastly, adapting the vulnerability management ecosystem for an AIdriven management ecosystem for an AIdriven management ecosystem for an AIdriven future. future. future. So given that we're at a vulnerability So given that we're at a vulnerability So given that we're at a vulnerability conference, I'm assuming that most of conference, I'm assuming that most of conference, I'm assuming that most of you are fairly familiar with these you are fairly familiar with these you are fairly familiar with these terms, but for those that are new to the terms, but for those that are new to the terms, but for those that are new to the area, I kind of want to level set so area, I kind of want to level set so area, I kind of want to level set so that we can figure out how AI plays into that we can figure out how AI plays into that we can figure out how AI plays into this uh current ecosystem. Um the four this uh current ecosystem. Um the four this uh current ecosystem. Um the four primary components of the current primary components of the current primary components of the current vulnerability software ecosystem are vulnerability software ecosystem are vulnerability software ecosystem are CVEes, CWE, CVSS, and CVD. So the common CVEes, CWE, CVSS, and CVD. So the common CVEes, CWE, CVSS, and CVD. So the common vulnerability and exposure CVE vulnerability and exposure CVE vulnerability and exposure CVE standardizes the identifiers for standardizes the identifiers for standardizes the identifiers for publicly known vulnerabilities providing publicly known vulnerabilities providing publicly known vulnerabilities providing unique IDs uh and references for unique IDs uh and references for unique IDs uh and references for specific flaws. Then we transition to specific flaws. Then we transition to specific flaws. Then we transition to CWES which is a taxonomy of root causes CWES which is a taxonomy of root causes CWES which is a taxonomy of root causes and software hardware weakness types and software hardware weakness types and software hardware weakness types that could lead to those that could lead to those that could lead to those vulnerabilities. So this could be vulnerabilities. So this could be vulnerabilities. So this could be anything from issues with buffer anything from issues with buffer anything from issues with buffer overflows, injection flaws and overflows, injection flaws and overflows, injection flaws and misconfigurations which help misconfigurations which help misconfigurations which help stakeholders to identify the underlying stakeholders to identify the underlying stakeholders to identify the underlying weaknesses in a system. Then we weaknesses in a system. Then we weaknesses in a system. Then we transition to the CVSS which assesses transition to the CVSS which assesses transition to the CVSS which assesses the severity of vulnerabilities and the severity of vulnerabilities and the severity of vulnerabilities and provides numeric scoring 0 to 10 and provides numeric scoring 0 to 10 and provides numeric scoring 0 to 10 and qualitative ratings low critical etc. qualitative ratings low critical etc. qualitative ratings low critical etc. This helps organizations to prioritize This helps organizations to prioritize This helps organizations to prioritize patching especially for critical patching especially for critical patching especially for critical vulnerabilities. But as we all know, the vulnerabilities. But as we all know, the vulnerabilities. But as we all know, the context really matters. In some uh context really matters. In some uh context really matters. In some uh organizations, a critical vulnerability organizations, a critical vulnerability organizations, a critical vulnerability really is a low because there are really is a low because there are really is a low because there are compensating controls in place. Um and compensating controls in place. Um and compensating controls in place. Um and then lastly, the coordinated then lastly, the coordinated then lastly, the coordinated vulnerability disclosure vulnerability disclosure vulnerability disclosure uh involves private reporting of bugs to uh involves private reporting of bugs to uh involves private reporting of bugs to vendors which allow time for fixes uh vendors which allow time for fixes uh vendors which allow time for fixes uh before public disclosure. So bug bounty before public disclosure. So bug bounty before public disclosure. So bug bounty programs facilitate this process, programs facilitate this process, programs facilitate this process, incentivizing safe reporting. These incentivizing safe reporting. These incentivizing safe reporting. These programs quickly uncover hidden programs quickly uncover hidden programs quickly uncover hidden vulnerabilities and foster vulnerabilities and foster vulnerabilities and foster collaboration. Though this list is collaboration. Though this list is collaboration. Though this list is comprehensive, it doesn't capture every comprehensive, it doesn't capture every comprehensive, it doesn't capture every component of the current ecosystem. For component of the current ecosystem. For component of the current ecosystem. For example, SIZA's uh KVE catalog and the example, SIZA's uh KVE catalog and the example, SIZA's uh KVE catalog and the EPSS scoring system that estimates the EPSS scoring system that estimates the EPSS scoring system that estimates the likelihood or probability that a likelihood or probability that a likelihood or probability that a software vulnerability will be exploited. So given the current exploited. So given the current exploited. So given the current ecosystem, how does AI play into all of ecosystem, how does AI play into all of ecosystem, how does AI play into all of this? There are new vulnerabilities and this? There are new vulnerabilities and this? There are new vulnerabilities and classification challenges introduced classification challenges introduced classification challenges introduced with AI models. with AI models. with AI models. First, there are vulnerabilities in AI First, there are vulnerabilities in AI First, there are vulnerabilities in AI software packages. These are our software packages. These are our software packages. These are our conventional software bugs in AI conventional software bugs in AI conventional software bugs in AI frameworks or libraries such as the frameworks or libraries such as the frameworks or libraries such as the exploitable bugs in TensorFlow or exploitable bugs in TensorFlow or exploitable bugs in TensorFlow or PyTorch. These are managed like any PyTorch. These are managed like any PyTorch. These are managed like any other software CVE and fit within the other software CVE and fit within the other software CVE and fit within the existing vulnerability management existing vulnerability management existing vulnerability management framework requiring no change to the framework requiring no change to the framework requiring no change to the current software vault current software vault current software vault ecosystem. Next, we have model behavior ecosystem. Next, we have model behavior ecosystem. Next, we have model behavior flaws. These are failures or undesirable flaws. These are failures or undesirable flaws. These are failures or undesirable behaviors of the model itself rather behaviors of the model itself rather behaviors of the model itself rather than bugs in the code. Some examples than bugs in the code. Some examples than bugs in the code. Some examples will include um when an AI model will include um when an AI model will include um when an AI model hallucinates or generates content that hallucinates or generates content that hallucinates or generates content that conflicts with input training data or is conflicts with input training data or is conflicts with input training data or is inconsistent with facts or um if a model inconsistent with facts or um if a model inconsistent with facts or um if a model is susceptible to prompt injection is susceptible to prompt injection is susceptible to prompt injection vulnerabilities where an attacker can vulnerabilities where an attacker can vulnerabilities where an attacker can create inputs designed to take the model create inputs designed to take the model create inputs designed to take the model uh to make the model behave in an uh to make the model behave in an uh to make the model behave in an unintended way. unintended way. unintended way. These differ from classic These differ from classic These differ from classic vulnerabilities as there is no vulnerabilities as there is no vulnerabilities as there is no underlying code error to patch and the underlying code error to patch and the underlying code error to patch and the flaw lies in the model training or flaw lies in the model training or flaw lies in the model training or logic. Lastly, we have issues spanning logic. Lastly, we have issues spanning logic. Lastly, we have issues spanning ethics and safety. These are categorized ethics and safety. These are categorized ethics and safety. These are categorized as broad A IML incidents and failures. as broad A IML incidents and failures. as broad A IML incidents and failures. And some examples of this And some examples of this And some examples of this include vision model failures in include vision model failures in include vision model failures in self-driving cars or bias in AI powered self-driving cars or bias in AI powered self-driving cars or bias in AI powered hiring systems. Honestly, bias in hiring systems. Honestly, bias in hiring systems. Honestly, bias in general when it comes to AI. And these general when it comes to AI. And these general when it comes to AI. And these don't fit neatly into the CBE paradigm don't fit neatly into the CBE paradigm don't fit neatly into the CBE paradigm as they aren't security violations being as they aren't security violations being as they aren't security violations being exploited, but they can have serious and exploited, but they can have serious and exploited, but they can have serious and lasting lasting lasting consequences. So with the introduction consequences. So with the introduction consequences. So with the introduction of these new vulnerabilities and of these new vulnerabilities and of these new vulnerabilities and classification challenges, this begs the classification challenges, this begs the classification challenges, this begs the question whether AI vulnerabilities can question whether AI vulnerabilities can question whether AI vulnerabilities can fit into this existing ecosystem with fit into this existing ecosystem with fit into this existing ecosystem with ease or if it's possible to create a ease or if it's possible to create a ease or if it's possible to create a whole new paradigm that responds to whole new paradigm that responds to whole new paradigm that responds to these challenges. So we conducted a comparative mapping of So we conducted a comparative mapping of So we conducted a comparative mapping of the current software vulnerability the current software vulnerability the current software vulnerability ecosystem and the AI vulnerability ecosystem and the AI vulnerability ecosystem and the AI vulnerability ecosystem to see where this is ecosystem to see where this is ecosystem to see where this is comparable where there are comparable comparable where there are comparable comparable where there are comparable alternatives with AI or gaps with these alternatives with AI or gaps with these alternatives with AI or gaps with these technologies and give you all a moment technologies and give you all a moment technologies and give you all a moment to take a picture if you want. to take a picture if you want. to take a picture if you want. But so we broke it out. No. Um so with this we look excuse me No. Um so with this we look excuse me No. Um so with this we look excuse me looked at a few different feature areas. looked at a few different feature areas. looked at a few different feature areas. I'm not going to go over this in broad I'm not going to go over this in broad I'm not going to go over this in broad detail but um just wanted to highlight a detail but um just wanted to highlight a detail but um just wanted to highlight a few callouts where a IML is um kind of few callouts where a IML is um kind of few callouts where a IML is um kind of on par with the traditional software on par with the traditional software on par with the traditional software vulnerabilities and where there might be vulnerabilities and where there might be vulnerabilities and where there might be some gaps or it's limited. Um firstly some gaps or it's limited. Um firstly some gaps or it's limited. Um firstly when it comes to vulnerability cataloges when it comes to vulnerability cataloges when it comes to vulnerability cataloges this is missing entirely on the a IML this is missing entirely on the a IML this is missing entirely on the a IML side. So there's no central side. So there's no central side. So there's no central comprehensive catalog equivalent to NVD comprehensive catalog equivalent to NVD comprehensive catalog equivalent to NVD linking unique IDs to details. Whereas linking unique IDs to details. Whereas linking unique IDs to details. Whereas on the traditional software on the traditional software on the traditional software vulnerability side um this is fairly vulnerability side um this is fairly vulnerability side um this is fairly comprehensive with NIST's NVD catalog um comprehensive with NIST's NVD catalog um comprehensive with NIST's NVD catalog um and then CIS Kev that tracks exploited and then CIS Kev that tracks exploited and then CIS Kev that tracks exploited vulnerabilities. Similarly looking at vulnerabilities. Similarly looking at vulnerabilities. Similarly looking at the attack taxonomy um on the the attack taxonomy um on the the attack taxonomy um on the traditional software vulnerability side traditional software vulnerability side traditional software vulnerability side we have MITER's attack framework which we have MITER's attack framework which we have MITER's attack framework which provides a broad taxonomy of adversary provides a broad taxonomy of adversary provides a broad taxonomy of adversary tactics across killchain stages and then tactics across killchain stages and then tactics across killchain stages and then on the a IML side we have MIT's atlas on the a IML side we have MIT's atlas on the a IML side we have MIT's atlas which catalogs the adversary tactics which catalogs the adversary tactics which catalogs the adversary tactics specifically against AI and ML systems. specifically against AI and ML systems. specifically against AI and ML systems. Um following up, there's also the Um following up, there's also the Um following up, there's also the incident databases that um are pretty incident databases that um are pretty incident databases that um are pretty established on the traditional software established on the traditional software established on the traditional software vulnerability side. Various databases vulnerability side. Various databases vulnerability side. Various databases exist like the privacy rights clearing exist like the privacy rights clearing exist like the privacy rights clearing house, Zywave, though these can be house, Zywave, though these can be house, Zywave, though these can be fragmented. And on the a IML side, um fragmented. And on the a IML side, um fragmented. And on the a IML side, um there's a specific focus with dedicated there's a specific focus with dedicated there's a specific focus with dedicated databases that are in development such databases that are in development such databases that are in development such as incident database.ai and the AI as incident database.ai and the AI as incident database.ai and the AI AIC. Lastly, wanted to talk about bug AIC. Lastly, wanted to talk about bug AIC. Lastly, wanted to talk about bug bounty programs or VDB platforms. Um, on bounty programs or VDB platforms. Um, on bounty programs or VDB platforms. Um, on the a IML side, this is currently the a IML side, this is currently the a IML side, this is currently emerging. There are platforms that exist emerging. There are platforms that exist emerging. There are platforms that exist such as hunter.com, but the market is such as hunter.com, but the market is such as hunter.com, but the market is less mature when comparing it to the less mature when comparing it to the less mature when comparing it to the traditional software vulnerability side. traditional software vulnerability side. traditional software vulnerability side. This is very established and mature um This is very established and mature um This is very established and mature um with platforms like Hacker One, Bug with platforms like Hacker One, Bug with platforms like Hacker One, Bug Crowd, Synac that have wide Crowd, Synac that have wide Crowd, Synac that have wide participation within the community. Going back to the to the four main Going back to the to the four main Going back to the to the four main components of the current software components of the current software components of the current software vulnerability ecosystem, I briefly vulnerability ecosystem, I briefly vulnerability ecosystem, I briefly discussed CVDs and now I want to discussed CVDs and now I want to discussed CVDs and now I want to introduce frameworks for AI introduce frameworks for AI introduce frameworks for AI vulnerability disclosure. Emerging vulnerability disclosure. Emerging vulnerability disclosure. Emerging frameworks like the CFD and CDDC aim to frameworks like the CFD and CDDC aim to frameworks like the CFD and CDDC aim to address AI model flaws. Um, so the address AI model flaws. Um, so the address AI model flaws. Um, so the coordinated flaw disclosure program was coordinated flaw disclosure program was coordinated flaw disclosure program was introduced by Catel and others last introduced by Catel and others last introduced by Catel and others last summer and it's tailored to adapt summer and it's tailored to adapt summer and it's tailored to adapt traditional vulnerability disclosure to traditional vulnerability disclosure to traditional vulnerability disclosure to AI's unique challenges. Some key AI's unique challenges. Some key AI's unique challenges. Some key features include structured reporting, features include structured reporting, features include structured reporting, extended model cards that specify the extended model cards that specify the extended model cards that specify the scope and intent of target AI systems, scope and intent of target AI systems, scope and intent of target AI systems, and an independent adjudication panel to and an independent adjudication panel to and an independent adjudication panel to mediate disputes between submitters and mediate disputes between submitters and mediate disputes between submitters and vendors. Emphasis is placed on vendors. Emphasis is placed on vendors. Emphasis is placed on transparency, accountability, and transparency, accountability, and transparency, accountability, and involving diverse stakeholders. a pilot. Just in Just in Just in case a pilot implementation was case a pilot implementation was case a pilot implementation was conducted at Defcon 32 last year and conducted at Defcon 32 last year and conducted at Defcon 32 last year and then they also proposed the common use then they also proposed the common use then they also proposed the common use enumeration that mirrors C.WE in an enumeration that mirrors C.WE in an enumeration that mirrors C.WE in an attempt to organize AI model uses attempt to organize AI model uses attempt to organize AI model uses hierarchically. hierarchically. hierarchically. Second, we have the coordinated Second, we have the coordinated Second, we have the coordinated disclosure of dual use capabilities disclosure of dual use capabilities disclosure of dual use capabilities which was proposed by O'Brien and others which was proposed by O'Brien and others which was proposed by O'Brien and others in 2024 as well and it addresses AI in 2024 as well and it addresses AI in 2024 as well and it addresses AI systems with dual use potential. CDDC systems with dual use potential. CDDC systems with dual use potential. CDDC acts as an early warning system acts as an early warning system acts as an early warning system recognizing unexpected dangerous recognizing unexpected dangerous recognizing unexpected dangerous capabilities in AI models. Finders will capabilities in AI models. Finders will capabilities in AI models. Finders will report risky capabilities to a central report risky capabilities to a central report risky capabilities to a central clearing house which then alerts clearing house which then alerts clearing house which then alerts appropriate defenders. The goal is to appropriate defenders. The goal is to appropriate defenders. The goal is to maximize society's time to prepare maximize society's time to prepare maximize society's time to prepare defenses emphasizing crossorganization defenses emphasizing crossorganization defenses emphasizing crossorganization communication. It complements model communication. It complements model communication. It complements model evaluation programs and red teaming evaluation programs and red teaming evaluation programs and red teaming efforts. Lastly, there are the AI flaw efforts. Lastly, there are the AI flaw efforts. Lastly, there are the AI flaw bounty programs that exist. Similar to bounty programs that exist. Similar to bounty programs that exist. Similar to the bug bounties, these reward users for the bug bounties, these reward users for the bug bounties, these reward users for finding and reporting AI model flaws finding and reporting AI model flaws finding and reporting AI model flaws such as what I mentioned earlier, such as what I mentioned earlier, such as what I mentioned earlier, hunter.com and Anthropics jailbreak hunter.com and Anthropics jailbreak hunter.com and Anthropics jailbreak challenge. Now I will turn it over to challenge. Now I will turn it over to challenge. Now I will turn it over to Kyle for part two of our presentation, Kyle for part two of our presentation, Kyle for part two of our presentation, increasing vulnerabilities in AI's increasing vulnerabilities in AI's increasing vulnerabilities in AI's potential impact. Hello everyone. Now this is stepping Hello everyone. Now this is stepping Hello everyone. Now this is stepping away from our original proposed away from our original proposed away from our original proposed presentation to highlight some of the presentation to highlight some of the presentation to highlight some of the research we're doing at Rand and uh we'd research we're doing at Rand and uh we'd research we're doing at Rand and uh we'd love to talk to you guys about this as love to talk to you guys about this as love to talk to you guys about this as we move forward. But um as we discussed we move forward. But um as we discussed we move forward. But um as we discussed here briefly you know we are seeing an here briefly you know we are seeing an here briefly you know we are seeing an increasing rise in CVEEs and uh increasing rise in CVEEs and uh increasing rise in CVEEs and uh proportional increase in uh CVSS scores proportional increase in uh CVSS scores proportional increase in uh CVSS scores showing um medium and high actually uh showing um medium and high actually uh showing um medium and high actually uh both increasing uh uh with the you know both increasing uh uh with the you know both increasing uh uh with the you know significant uptick we've seen this year significant uptick we've seen this year significant uptick we've seen this year in uh or 2024 in uh CVEes coming online in uh or 2024 in uh CVEes coming online in uh or 2024 in uh CVEes coming online and has been mentioned several times at and has been mentioned several times at and has been mentioned several times at this conference. uh it's not always the this conference. uh it's not always the this conference. uh it's not always the significant vulnerabilities that are a significant vulnerabilities that are a significant vulnerabilities that are a problem but it's the massive scale of problem but it's the massive scale of problem but it's the massive scale of even medium and low um chain together even medium and low um chain together even medium and low um chain together that could be a significant threat. This that could be a significant threat. This that could be a significant threat. This of course puts a huge strain on uh of course puts a huge strain on uh of course puts a huge strain on uh security researchers uh as these security researchers uh as these security researchers uh as these increase and uh you know this happens increase and uh you know this happens increase and uh you know this happens for a lot of reasons right new software for a lot of reasons right new software for a lot of reasons right new software um expansion of IoT um in different uh um expansion of IoT um in different uh um expansion of IoT um in different uh areas as well as just better reporting areas as well as just better reporting areas as well as just better reporting standards. So it's not that um you know standards. So it's not that um you know standards. So it's not that um you know there's a massive increase of threats there's a massive increase of threats there's a massive increase of threats but uh you know there is that as well. but uh you know there is that as well. but uh you know there is that as well. Now um the main goal of our research Now um the main goal of our research Now um the main goal of our research really is to look at the impact of AI on really is to look at the impact of AI on really is to look at the impact of AI on uh on all these uh systems whether we're uh on all these uh systems whether we're uh on all these uh systems whether we're going to see a significant increase in going to see a significant increase in going to see a significant increase in novel AI vulnerabilities. It's one of novel AI vulnerabilities. It's one of novel AI vulnerabilities. It's one of the ones DA talked about or uh you know the ones DA talked about or uh you know the ones DA talked about or uh you know whether we're just going to see a flood whether we're just going to see a flood whether we're just going to see a flood of CVES and how do security researchers of CVES and how do security researchers of CVES and how do security researchers deal with that. And uh I created this uh deal with that. And uh I created this uh deal with that. And uh I created this uh speculative chart just to show what that speculative chart just to show what that speculative chart just to show what that could look like um with uh from 2025 a could look like um with uh from 2025 a could look like um with uh from 2025 a proportional increase in uh CVEes a nice proportional increase in uh CVEes a nice proportional increase in uh CVEes a nice jump there with uh similar CVSS scores. jump there with uh similar CVSS scores. jump there with uh similar CVSS scores. Um and then you know what if we see a Um and then you know what if we see a Um and then you know what if we see a jump like we did in 2017 with 122%. in jump like we did in 2017 with 122%. in jump like we did in 2017 with 122%. in 2026 if uh um so that's one of the big 2026 if uh um so that's one of the big 2026 if uh um so that's one of the big questions will uh will AI systems as questions will uh will AI systems as questions will uh will AI systems as they uh become more capable actually they uh become more capable actually they uh become more capable actually benefit you know the offense or defense benefit you know the offense or defense benefit you know the offense or defense and what that could look like I mean and what that could look like I mean and what that could look like I mean with a rapid increase I think 122 might with a rapid increase I think 122 might with a rapid increase I think 122 might be actually on the lower end uh we be actually on the lower end uh we be actually on the lower end uh we really don't know at this time but uh really don't know at this time but uh really don't know at this time but uh that's an important research question that's an important research question that's an important research question we're looking into we're looking into we're looking into um okay so first is uh looking at um um okay so first is uh looking at um um okay so first is uh looking at um just AI I accelerated vulnerability just AI I accelerated vulnerability just AI I accelerated vulnerability disclosure. Now um you know this is a disclosure. Now um you know this is a disclosure. Now um you know this is a hot topic as well or discovery sorry not hot topic as well or discovery sorry not hot topic as well or discovery sorry not disclosure but um you know we see disclosure but um you know we see disclosure but um you know we see increased uh uh capabilities helping increased uh uh capabilities helping increased uh uh capabilities helping with uh analysis of code to identify with uh analysis of code to identify with uh analysis of code to identify vulnerabilities. You the big one here is vulnerabilities. You the big one here is vulnerabilities. You the big one here is uh you know the increasing capabilities uh you know the increasing capabilities uh you know the increasing capabilities of AI agents. I know a lot of the of AI agents. I know a lot of the of AI agents. I know a lot of the vendors out here have developed tools to vendors out here have developed tools to vendors out here have developed tools to identify uh vulnerabilities and even go identify uh vulnerabilities and even go identify uh vulnerabilities and even go as far as moving towards patching as as far as moving towards patching as as far as moving towards patching as things become more capable. Um and you things become more capable. Um and you things become more capable. Um and you see projects like uh Google's deep sleep see projects like uh Google's deep sleep see projects like uh Google's deep sleep um and uh code intelligence their their um and uh code intelligence their their um and uh code intelligence their their tool. I mean there's quite a few out tool. I mean there's quite a few out tool. I mean there's quite a few out there that are doing a good job at uh there that are doing a good job at uh there that are doing a good job at uh identifying these vulnerabilities which identifying these vulnerabilities which identifying these vulnerabilities which you know would be great benefit to uh to you know would be great benefit to uh to you know would be great benefit to uh to researchers and uh we're seeing a lot of researchers and uh we're seeing a lot of researchers and uh we're seeing a lot of a lot of uh you know efforts to use LLMs a lot of uh you know efforts to use LLMs a lot of uh you know efforts to use LLMs to scan just significantly large uh code to scan just significantly large uh code to scan just significantly large uh code bases to see if they can identify um bases to see if they can identify um bases to see if they can identify um vulnerabilities much faster or uh or vulnerabilities much faster or uh or vulnerabilities much faster or uh or even identify new vulnerabilities across even identify new vulnerabilities across even identify new vulnerabilities across a much larger space. Now the next of a much larger space. Now the next of a much larger space. Now the next of course is AIdriven fuzzing. You know course is AIdriven fuzzing. You know course is AIdriven fuzzing. You know integrating a lot of the uh jumps in LLM integrating a lot of the uh jumps in LLM integrating a lot of the uh jumps in LLM into uh traditional security tools and into uh traditional security tools and into uh traditional security tools and some of these is OSS fuzz I know is one some of these is OSS fuzz I know is one some of these is OSS fuzz I know is one that's also with the Google team um CI that's also with the Google team um CI that's also with the Google team um CI fuzz from code intelligence and many fuzz from code intelligence and many fuzz from code intelligence and many more um you know to develop high quality more um you know to develop high quality more um you know to develop high quality test cases and you know this really does test cases and you know this really does test cases and you know this really does have the potential to really decrease have the potential to really decrease have the potential to really decrease the time it takes to look over the time it takes to look over the time it takes to look over significant code bases and identify significant code bases and identify significant code bases and identify these vulnerabilities. Um you know we it these vulnerabilities. Um you know we it these vulnerabilities. Um you know we it the jury is still out on how uh the jury is still out on how uh the jury is still out on how uh effective this will be but we are seeing effective this will be but we are seeing effective this will be but we are seeing you know pretty radical improvements and you know pretty radical improvements and you know pretty radical improvements and how this could help us in that area. But how this could help us in that area. But how this could help us in that area. But uh ultimately this could be a uh ultimately this could be a uh ultimately this could be a double-edged sword where uh you know double-edged sword where uh you know double-edged sword where uh you know attackers able to actually identify attackers able to actually identify attackers able to actually identify vulnerability discovers and uh and weak vulnerability discovers and uh and weak vulnerability discovers and uh and weak points within those code base to points within those code base to points within those code base to actually target these areas and uh you actually target these areas and uh you actually target these areas and uh you know as AI tools are complemented with know as AI tools are complemented with know as AI tools are complemented with uh you know generative AI and and uh you know generative AI and and uh you know generative AI and and different uh possible paradigms that different uh possible paradigms that different uh possible paradigms that come online uh we definitely have to come online uh we definitely have to come online uh we definitely have to keep an eye out for keep an eye out for keep an eye out for that. And uh on that note, AI augmented that. And uh on that note, AI augmented that. And uh on that note, AI augmented exploitation also a very popular topic. exploitation also a very popular topic. exploitation also a very popular topic. Now um you I'd say one of the first Now um you I'd say one of the first Now um you I'd say one of the first things that uh that we're looking at things that uh that we're looking at things that uh that we're looking at significantly at Rand and this uh will significantly at Rand and this uh will significantly at Rand and this uh will be a part of our vulnerability discovery be a part of our vulnerability discovery be a part of our vulnerability discovery uh research is capability uplift. you uh research is capability uplift. you uh research is capability uplift. you know, can these new tools uh increase know, can these new tools uh increase know, can these new tools uh increase the ability of less sophisticated actors the ability of less sophisticated actors the ability of less sophisticated actors to, you know, be able to identify to, you know, be able to identify to, you know, be able to identify vulnerabilities, get the skills needed vulnerabilities, get the skills needed vulnerabilities, get the skills needed uh to execute exploits, and you know, uh to execute exploits, and you know, uh to execute exploits, and you know, we've seen some models come online. Um, we've seen some models come online. Um, we've seen some models come online. Um, I forget the name of a few of them uh I forget the name of a few of them uh I forget the name of a few of them uh used to help develop malware. Um, and used to help develop malware. Um, and used to help develop malware. Um, and those are out there, and I think they those are out there, and I think they those are out there, and I think they will increase in sophistication as we will increase in sophistication as we will increase in sophistication as we move forward. And uh and that's the move forward. And uh and that's the move forward. And uh and that's the democratized access, you know, whether democratized access, you know, whether democratized access, you know, whether low-skilled actors able to increase low-skilled actors able to increase low-skilled actors able to increase their capabilities or new actors that their capabilities or new actors that their capabilities or new actors that might actually be able to enter the might actually be able to enter the might actually be able to enter the space as opposed to cyber security space as opposed to cyber security space as opposed to cyber security experts. Um social engineering, that's experts. Um social engineering, that's experts. Um social engineering, that's another one. I know there's been a lot another one. I know there's been a lot another one. I know there's been a lot of tests out there to see if we can of tests out there to see if we can of tests out there to see if we can develop sophisticated uh fishing emails develop sophisticated uh fishing emails develop sophisticated uh fishing emails uh more confing more convincing fishing uh more confing more convincing fishing uh more confing more convincing fishing emails uh to send out to a much wider emails uh to send out to a much wider emails uh to send out to a much wider audience to uh uh really get after uh audience to uh uh really get after uh audience to uh uh really get after uh various companies out there and um various companies out there and um various companies out there and um develop exploits much on a much larger develop exploits much on a much larger develop exploits much on a much larger scale. You know, we haven't seen this scale. You know, we haven't seen this scale. You know, we haven't seen this that much yet, but really being able to that much yet, but really being able to that much yet, but really being able to flood the zone with the quantity of flood the zone with the quantity of flood the zone with the quantity of different malware and fishing emails different malware and fishing emails different malware and fishing emails could become a significant threat for uh could become a significant threat for uh could become a significant threat for uh for uh you know sensitive companies out for uh you know sensitive companies out for uh you know sensitive companies out there. And then of course the big one is there. And then of course the big one is there. And then of course the big one is autonomous agents and uh like I was autonomous agents and uh like I was autonomous agents and uh like I was saying talking to a lot of the vendors saying talking to a lot of the vendors saying talking to a lot of the vendors this week um agents are exploding that's this week um agents are exploding that's this week um agents are exploding that's uh especially as become more capable. uh especially as become more capable. uh especially as become more capable. what even a year ago uh we saw very what even a year ago uh we saw very what even a year ago uh we saw very little capabilities for agents to little capabilities for agents to little capabilities for agents to actually be able to um complete actually be able to um complete actually be able to um complete multi-step processes autonomously but uh multi-step processes autonomously but uh multi-step processes autonomously but uh I think it was meter meter the I think it was meter meter the I think it was meter meter the evaluation company did a report like a evaluation company did a report like a evaluation company did a report like a week or two ago that looked at AI agents week or two ago that looked at AI agents week or two ago that looked at AI agents capability to go through and do capability to go through and do capability to go through and do multi-step tasks and what that looks multi-step tasks and what that looks multi-step tasks and what that looks like and they're seeing a doubling time like and they're seeing a doubling time like and they're seeing a doubling time about every seven months where the about every seven months where the about every seven months where the models are able to increase their models are able to increase their models are able to increase their ability to uh reach human level or ability to uh reach human level or ability to uh reach human level or human, you know, like tasks in uh um you human, you know, like tasks in uh um you human, you know, like tasks in uh um you know, hours to possibly days in the next know, hours to possibly days in the next know, hours to possibly days in the next uh but right now multi multi-hour uh but right now multi multi-hour uh but right now multi multi-hour projects be able to go through the projects be able to go through the projects be able to go through the entire steps of the kill chain and uh entire steps of the kill chain and uh entire steps of the kill chain and uh that's looks like it's coming. It's that's looks like it's coming. It's that's looks like it's coming. It's becoming much more effective. So that's becoming much more effective. So that's becoming much more effective. So that's something to look out for and um yeah, something to look out for and um yeah, something to look out for and um yeah, there's multiple reports have come out there's multiple reports have come out there's multiple reports have come out recently on using LLM uh to really find recently on using LLM uh to really find recently on using LLM uh to really find these vulnerabilities, develop the these vulnerabilities, develop the these vulnerabilities, develop the exploits and uh and really complete exploits and uh and really complete exploits and uh and really complete multi-stage targets. And I know OASP multi-stage targets. And I know OASP multi-stage targets. And I know OASP came out with a great report on agents, came out with a great report on agents, came out with a great report on agents, top 10 on agents that I encourage top 10 on agents that I encourage top 10 on agents that I encourage everyone to look at. It's everyone to look at. It's everyone to look at. It's spectacular. And um then of course spectacular. And um then of course spectacular. And um then of course defense now majority of researchers out defense now majority of researchers out defense now majority of researchers out there are uh are saying that uh they there are uh are saying that uh they there are uh are saying that uh they believe that believe that believe that new new innovations in AI will really new new innovations in AI will really new new innovations in AI will really benefit defenders more than anything. benefit defenders more than anything. benefit defenders more than anything. that's in the offense defense balance that's in the offense defense balance that's in the offense defense balance because we're seeing uh you know because we're seeing uh you know because we're seeing uh you know increases along a vi you know wide increases along a vi you know wide increases along a vi you know wide spectrum of possible use cases you know spectrum of possible use cases you know spectrum of possible use cases you know a big one is improved threat detection a big one is improved threat detection a big one is improved threat detection and real-time monitoring we're seeing and real-time monitoring we're seeing and real-time monitoring we're seeing that uh integrating AI into a lot of that uh integrating AI into a lot of that uh integrating AI into a lot of these tools we're able to you know scan these tools we're able to you know scan these tools we're able to you know scan much larger area and be able to identify much larger area and be able to identify much larger area and be able to identify identify threats through significant identify threats through significant identify threats through significant volumes look for you know just small volumes look for you know just small volumes look for you know just small deviations in the patterns to identify deviations in the patterns to identify deviations in the patterns to identify what could be malicious activity um so what could be malicious activity um so what could be malicious activity um so that's an area that's improving rapidly that's an area that's improving rapidly that's an area that's improving rapidly ly then of course alert reduction you ly then of course alert reduction you ly then of course alert reduction you know having these uh more significant know having these uh more significant know having these uh more significant tools that identify you know small tools that identify you know small tools that identify you know small signals in the noise that might indicate signals in the noise that might indicate signals in the noise that might indicate um that an attack is underway or unique um that an attack is underway or unique um that an attack is underway or unique tech is underway um could be a huge tech is underway um could be a huge tech is underway um could be a huge uplift for security researchers out uplift for security researchers out uplift for security researchers out there to be identify problems that might there to be identify problems that might there to be identify problems that might be coming. Now one of the big issues of be coming. Now one of the big issues of be coming. Now one of the big issues of course is uh some of the explanability course is uh some of the explanability course is uh some of the explanability challenges you have with AI uh you know challenges you have with AI uh you know challenges you have with AI uh you know AI models deep learning especially uh do AI models deep learning especially uh do AI models deep learning especially uh do have the tendency to uh you know have have the tendency to uh you know have have the tendency to uh you know have failure modes come up with mistakes or failure modes come up with mistakes or failure modes come up with mistakes or identify something as malicious that identify something as malicious that identify something as malicious that might not be and I'd say you know the might not be and I'd say you know the might not be and I'd say you know the biggest issue of course is uh you know biggest issue of course is uh you know biggest issue of course is uh you know it's inability to explain why and we're it's inability to explain why and we're it's inability to explain why and we're seeing this across a ton of fields right seeing this across a ton of fields right seeing this across a ton of fields right um with integrating um with integrating um with integrating you know deep learning into uh the you know deep learning into uh the you know deep learning into uh the intelligence community for example or intelligence community for example or intelligence community for example or defense applications I mean these are defense applications I mean these are defense applications I mean these are really high stakes so really having you really high stakes so really having you really high stakes so really having you know better interpretability in the know better interpretability in the know better interpretability in the models uh it is huge as we move forward models uh it is huge as we move forward models uh it is huge as we move forward especially as we get those multi-stage especially as we get those multi-stage especially as we get those multi-stage processes and uh if we don't understand processes and uh if we don't understand processes and uh if we don't understand what's actually happening under the hood what's actually happening under the hood what's actually happening under the hood it's uh more difficult um through came it's uh more difficult um through came it's uh more difficult um through came out with a pro paper I think I think out with a pro paper I think I think out with a pro paper I think I think with this last week that goes through uh with this last week that goes through uh with this last week that goes through uh just a ton of interpretability work I just a ton of interpretability work I just a ton of interpretability work I recommend everybody body give it a recommend everybody body give it a recommend everybody body give it a search if you haven't seen it. Um but it search if you haven't seen it. Um but it search if you haven't seen it. Um but it was a great step in understanding what was a great step in understanding what was a great step in understanding what the models are actually doing and how the models are actually doing and how the models are actually doing and how they're making their decisions there. they're making their decisions there. they're making their decisions there. Now of course another one is adversarial Now of course another one is adversarial Now of course another one is adversarial attacks. um you know there's some attacks. um you know there's some attacks. um you know there's some research out there that uh is quite research out there that uh is quite research out there that uh is quite novel looking at how to get around a lot novel looking at how to get around a lot novel looking at how to get around a lot of these AI based um uh adversarial of these AI based um uh adversarial of these AI based um uh adversarial attacks by you know manipulating the attacks by you know manipulating the attacks by you know manipulating the input data and you know different ways input data and you know different ways input data and you know different ways of actually getting through uh you know of actually getting through uh you know of actually getting through uh you know AI detection systems which is really AI detection systems which is really AI detection systems which is really interesting work out there. Now one interesting work out there. Now one interesting work out there. Now one other point I'd like to mention is uh other point I'd like to mention is uh other point I'd like to mention is uh reinforcement learning. A lot of these reinforcement learning. A lot of these reinforcement learning. A lot of these uh uh new tools under development use uh uh uh new tools under development use uh uh uh new tools under development use uh reinforcement learning to uh you know reinforcement learning to uh you know reinforcement learning to uh you know train on new code and just get better train on new code and just get better train on new code and just get better and better. But uh you know there's been and better. But uh you know there's been and better. But uh you know there's been significant errors in reinforcement significant errors in reinforcement significant errors in reinforcement learning in the past um things like learning in the past um things like learning in the past um things like reward hacking specification gaming uh reward hacking specification gaming uh reward hacking specification gaming uh so as we integrate AI into more so as we integrate AI into more so as we integrate AI into more important processes we have to look out important processes we have to look out important processes we have to look out for these failure modes that uh could be for these failure modes that uh could be for these failure modes that uh could be a significant issue. Just a little note a significant issue. Just a little note a significant issue. Just a little note there on challenges. there on challenges. there on challenges. All right. Well, as I said, this is a All right. Well, as I said, this is a All right. Well, as I said, this is a current project that Sasha, myself, and current project that Sasha, myself, and current project that Sasha, myself, and DA are working on. So, we have a ton of DA are working on. So, we have a ton of DA are working on. So, we have a ton of research questions that we're looking research questions that we're looking research questions that we're looking into here. Um, you know, one of the big into here. Um, you know, one of the big into here. Um, you know, one of the big ones, of course, is AI capabilities and ones, of course, is AI capabilities and ones, of course, is AI capabilities and limitations themselves. So, really just limitations themselves. So, really just limitations themselves. So, really just digging into, you know, what are the digging into, you know, what are the digging into, you know, what are the potential future uh changes? you know, potential future uh changes? you know, potential future uh changes? you know, how extreme could those be like I was how extreme could those be like I was how extreme could those be like I was saying, you know, could we see a saying, you know, could we see a saying, you know, could we see a absolute flood in CVES and how could uh absolute flood in CVES and how could uh absolute flood in CVES and how could uh um security teams actually deal with um security teams actually deal with um security teams actually deal with that or are we going to see some of the that or are we going to see some of the that or are we going to see some of the novel behavioral threats um unique AI novel behavioral threats um unique AI novel behavioral threats um unique AI based uh uh you know failures and based uh uh you know failures and based uh uh you know failures and vulnerabilities that DA spoke out in the vulnerabilities that DA spoke out in the vulnerabilities that DA spoke out in the first half of this and uh which actors first half of this and uh which actors first half of this and uh which actors could this enable? I mean, are we going could this enable? I mean, are we going could this enable? I mean, are we going to see SCA companies uh the intelligence to see SCA companies uh the intelligence to see SCA companies uh the intelligence community, the DoD um or the threat community, the DoD um or the threat community, the DoD um or the threat actors themselves? Are we going to see actors themselves? Are we going to see actors themselves? Are we going to see this benefit only sophisticated actors this benefit only sophisticated actors this benefit only sophisticated actors like AP groups? Are we going to see it like AP groups? Are we going to see it like AP groups? Are we going to see it in ransomware? Um these are all in ransomware? Um these are all in ransomware? Um these are all interesting questions that need to be um interesting questions that need to be um interesting questions that need to be um pursued. Now, of course, the next would pursued. Now, of course, the next would pursued. Now, of course, the next would be a class type of vulnerabilities. Is be a class type of vulnerabilities. Is be a class type of vulnerabilities. Is something we're going to see more of something we're going to see more of something we're going to see more of across various software um IoT SCADA um across various software um IoT SCADA um across various software um IoT SCADA um or uh you know various types of code or uh you know various types of code or uh you know various types of code where where could we expect to see uh where where could we expect to see uh where where could we expect to see uh vulnerability discover discovery on a vulnerability discover discovery on a vulnerability discover discovery on a large scale? Um and of you know types of large scale? Um and of you know types of large scale? Um and of you know types of systems. Exactly. Now and of course systems. Exactly. Now and of course systems. Exactly. Now and of course looking at the offense defense balance looking at the offense defense balance looking at the offense defense balance that's not going to be a focus of this that's not going to be a focus of this that's not going to be a focus of this project. Uh we likely need to do a whole project. Uh we likely need to do a whole project. Uh we likely need to do a whole separate project on that but really separate project on that but really separate project on that but really looking on who's going to benefit more. looking on who's going to benefit more. looking on who's going to benefit more. You know are we going to see defense You know are we going to see defense You know are we going to see defense become the most capable um or really you become the most capable um or really you become the most capable um or really you know receive the most benefit from know receive the most benefit from know receive the most benefit from integrating AI systems into uh into integrating AI systems into uh into integrating AI systems into uh into their existing tools or using LMS for their existing tools or using LMS for their existing tools or using LMS for much broader cases. uh or uh AI agents much broader cases. uh or uh AI agents much broader cases. uh or uh AI agents across multiple steps, you know, which across multiple steps, you know, which across multiple steps, you know, which one of those are going to benefit more one of those are going to benefit more one of those are going to benefit more and uh you know, changes in exploitation and uh you know, changes in exploitation and uh you know, changes in exploitation behavior, things like that. And uh we behavior, things like that. And uh we behavior, things like that. And uh we plan to do quite a bit of interviews and plan to do quite a bit of interviews and plan to do quite a bit of interviews and really try to develop, you know, what really try to develop, you know, what really try to develop, you know, what what this could look like from very low what this could look like from very low what this could look like from very low capability to very high capability. Um capability to very high capability. Um capability to very high capability. Um there could be no changes at all or we there could be no changes at all or we there could be no changes at all or we could see significant change and that's could see significant change and that's could see significant change and that's the whole point of this one. And then uh the whole point of this one. And then uh the whole point of this one. And then uh we want to look into developing we want to look into developing we want to look into developing resilient policy solutions to really resilient policy solutions to really resilient policy solutions to really contend with this. um you know how how contend with this. um you know how how contend with this. um you know how how do we deal with uh how can the uh CVE do we deal with uh how can the uh CVE do we deal with uh how can the uh CVE ecosystem uh really adapt to manage ecosystem uh really adapt to manage ecosystem uh really adapt to manage novel uh vulnerabilities, novel threats novel uh vulnerabilities, novel threats novel uh vulnerabilities, novel threats um or just significant quantity of new um or just significant quantity of new um or just significant quantity of new vulnerabilities discovered and will that vulnerabilities discovered and will that vulnerabilities discovered and will that benefit exploitation discovery or benefit exploitation discovery or benefit exploitation discovery or defense the defenders which you know is defense the defenders which you know is defense the defenders which you know is uh is being thought of as the most uh is being thought of as the most uh is being thought of as the most likely beneficiary at this time. Uh but likely beneficiary at this time. Uh but likely beneficiary at this time. Uh but that's it. Those are the uh those are that's it. Those are the uh those are that's it. Those are the uh those are the big research questions. We have many the big research questions. We have many the big research questions. We have many more, but uh this is the general area more, but uh this is the general area more, but uh this is the general area that we're looking at and uh yeah, we'd that we're looking at and uh yeah, we'd that we're looking at and uh yeah, we'd appreciate talking to any and every one appreciate talking to any and every one appreciate talking to any and every one of you about uh where you think this is of you about uh where you think this is of you about uh where you think this is going. But without any further, I'll going. But without any further, I'll going. But without any further, I'll pass this back to uh pass this back to uh pass this back to uh D or I guess we're D or I guess we're D or I guess we're done. I thought we had another section done. I thought we had another section done. I thought we had another section there, but yeah, we we do have a couple of minutes for we we do have a couple of minutes for we we do have a couple of minutes for Q&amp;A and uh there's one in the discord Q&amp;A and uh there's one in the discord Q&amp;A and uh there's one in the discord channel, so I'll kick it off with that. channel, so I'll kick it off with that. channel, so I'll kick it off with that. Uh vulnerabilities in AI systems made up Uh vulnerabilities in AI systems made up Uh vulnerabilities in AI systems made up of the AI model and software of the AI model and software of the AI model and software interfaces/solution can be either in the interfaces/solution can be either in the interfaces/solution can be either in the software or due to AI model flaw. Are software or due to AI model flaw. Are software or due to AI model flaw. Are you suggesting we follow different you suggesting we follow different you suggesting we follow different vulnerability tracking process standards vulnerability tracking process standards vulnerability tracking process standards for AI systems? So when it comes to AI systems? So when it comes to AI systems? So when it comes to AI vulnerabilities in the vulnerabilities in the vulnerabilities in the um in the software itself, we would um in the software itself, we would um in the software itself, we would maintain status quo. When it comes to maintain status quo. When it comes to maintain status quo. When it comes to model behavior flaws, that's something model behavior flaws, that's something model behavior flaws, that's something that is we're trying to develop um a that is we're trying to develop um a that is we're trying to develop um a framework to handle those framework to handle those framework to handle those vulnerabilities as they don't um they vulnerabilities as they don't um they vulnerabilities as they don't um they don't perform the same way that a don't perform the same way that a don't perform the same way that a software vulnerability would. Hi, uh great presentation. Looking Hi, uh great presentation. Looking Hi, uh great presentation. Looking forward to chatting. Um, when you were forward to chatting. Um, when you were forward to chatting. Um, when you were talking about sort of the potential for talking about sort of the potential for talking about sort of the potential for AI and that offense defense thing, I AI and that offense defense thing, I AI and that offense defense thing, I think that there's a hole here to talk think that there's a hole here to talk think that there's a hole here to talk about which is the humans. Um, and I about which is the humans. Um, and I about which is the humans. Um, and I would predict that a lot of the attacks would predict that a lot of the attacks would predict that a lot of the attacks that are going to happen are going to be that are going to happen are going to be that are going to happen are going to be social engineering that is augmented and social engineering that is augmented and social engineering that is augmented and scaled through AI. One person can now do scaled through AI. One person can now do scaled through AI. One person can now do attacks on a lot more people in a much attacks on a lot more people in a much attacks on a lot more people in a much more convincing way. And whether it is more convincing way. And whether it is more convincing way. And whether it is finding new vulnerabilities at scale or finding new vulnerabilities at scale or finding new vulnerabilities at scale or you know attacking them in various ways you know attacking them in various ways you know attacking them in various ways the scale problem will be human the scale problem will be human the scale problem will be human processes. So you talked about you know processes. So you talked about you know processes. So you talked about you know finding more vulnerabilities or uh you finding more vulnerabilities or uh you finding more vulnerabilities or uh you know whether it's attackers or know whether it's attackers or know whether it's attackers or whatever thinking about open source whatever thinking about open source whatever thinking about open source maintainers trying to handle they're maintainers trying to handle they're maintainers trying to handle they're already drowning in AI generated noise already drowning in AI generated noise already drowning in AI generated noise of vulnerabilities. every researcher of vulnerabilities. every researcher of vulnerabilities. every researcher thinks they're now going to win by, you thinks they're now going to win by, you thinks they're now going to win by, you know, running CodeQL a few thousand know, running CodeQL a few thousand know, running CodeQL a few thousand times. And uh and so we're we're times. And uh and so we're we're times. And uh and so we're we're creating a situation where the creating a situation where the creating a situation where the conventions of normal human interactions conventions of normal human interactions conventions of normal human interactions are going to get stressed. And so even are going to get stressed. And so even are going to get stressed. And so even just validating that you're the human just validating that you're the human just validating that you're the human I'm supposed to be talking to when I I'm supposed to be talking to when I I'm supposed to be talking to when I call you up to give you all my really call you up to give you all my really call you up to give you all my really great insights about how we're going to great insights about how we're going to great insights about how we're going to take over the world, I now, you know, take over the world, I now, you know, take over the world, I now, you know, our validation process of are you our validation process of are you our validation process of are you actually the person I'm talking to is actually the person I'm talking to is actually the person I'm talking to is rapidly falling into a dangerous place. rapidly falling into a dangerous place. rapidly falling into a dangerous place. And so I think as you look across this And so I think as you look across this And so I think as you look across this whole whole whole space recognizing where the con the space recognizing where the con the space recognizing where the con the human scale connection will create all human scale connection will create all human scale connection will create all kinds of breakages whether it's kinds of breakages whether it's kinds of breakages whether it's implementing code or responding to a implementing code or responding to a implementing code or responding to a prompt or a challenge or a security prompt or a challenge or a security prompt or a challenge or a security question. These are really important question. These are really important question. These are really important things. I'd love to talk more about it. things. I'd love to talk more about it. things. I'd love to talk more about it. I there's no question there by the way. I there's no question there by the way. I there's no question there by the way. I'm just making a statement. Yeah just I'm just making a statement. Yeah just I'm just making a statement. Yeah just quick response on that. Anyways, uh quick response on that. Anyways, uh quick response on that. Anyways, uh yeah, I think you highlighted something yeah, I think you highlighted something yeah, I think you highlighted something very important and um uh we really have very important and um uh we really have very important and um uh we really have to pay attention to where where this is to pay attention to where where this is to pay attention to where where this is going because I know there's a impulse going because I know there's a impulse going because I know there's a impulse to start automating everything as uh to start automating everything as uh to start automating everything as uh humans become much more involved in this humans become much more involved in this humans become much more involved in this and that's where the AI agents component and that's where the AI agents component and that's where the AI agents component is something we have to watch really is something we have to watch really is something we have to watch really closely um because folks are just closely um because folks are just closely um because folks are just looking to really analyze all these looking to really analyze all these looking to really analyze all these stages um and uh yeah it could be you stages um and uh yeah it could be you stages um and uh yeah it could be you know it's going to be an interesting know it's going to be an interesting know it's going to be an interesting couple years as we see uh you know couple years as we see uh you know couple years as we see uh you know multi-step multi-step multi-step you know, analysis of all these you know, analysis of all these you know, analysis of all these processes in the kill chain and uh and processes in the kill chain and uh and processes in the kill chain and uh and you know, you could see a future where you know, you could see a future where you know, you could see a future where you know, we we start moving towards you know, we we start moving towards you know, we we start moving towards robot versus robot and pull the human robot versus robot and pull the human robot versus robot and pull the human out of the uh out of the loop entirely. out of the uh out of the loop entirely. out of the uh out of the loop entirely. But uh yeah, with uh some of the But uh yeah, with uh some of the But uh yeah, with uh some of the increases automated fishing, um there's increases automated fishing, um there's increases automated fishing, um there's uh significant threats threats out there uh significant threats threats out there uh significant threats threats out there that we have to keep our eye that we have to keep our eye that we have to keep our eye on. Thanks for the question. Be happy to on. Thanks for the question. Be happy to on. Thanks for the question. Be happy to chat. chat. chat. Hi, I also have a question about your Hi, I also have a question about your Hi, I also have a question about your last slide. So, those are some really last slide. So, those are some really last slide. So, those are some really important obviously research questions important obviously research questions important obviously research questions that you ask. I'm curious about the that you ask. I'm curious about the that you ask. I'm curious about the signal. Like it's super hard to figure signal. Like it's super hard to figure signal. Like it's super hard to figure out which actors are doing these and you out which actors are doing these and you out which actors are doing these and you know the signal. So, I'm just curious know the signal. So, I'm just curious know the signal. So, I'm just curious what you're thinking about how you're what you're thinking about how you're what you're thinking about how you're going to detect and quantify some of going to detect and quantify some of going to detect and quantify some of these things. these things. these things. Yeah, that's extremely difficult. you Yeah, that's extremely difficult. you Yeah, that's extremely difficult. you know there's a ton of research streams know there's a ton of research streams know there's a ton of research streams out there right now that uh what is it I out there right now that uh what is it I out there right now that uh what is it I think Cybench a ton of evaluation think Cybench a ton of evaluation think Cybench a ton of evaluation frameworks being developed to uh work on frameworks being developed to uh work on frameworks being developed to uh work on you know identifying where these you you know identifying where these you you know identifying where these you know what are the capabilities of the know what are the capabilities of the know what are the capabilities of the model where are the threats coming from model where are the threats coming from model where are the threats coming from so that is a big part of the research is so that is a big part of the research is so that is a big part of the research is talking to experts out there and really talking to experts out there and really talking to experts out there and really determining uh the best path forward and determining uh the best path forward and determining uh the best path forward and uh yeah really being able to narrow down uh yeah really being able to narrow down uh yeah really being able to narrow down who the actors are who's benefiting um who the actors are who's benefiting um who the actors are who's benefiting um is a is a difficult challenge and uh is a is a difficult challenge and uh is a is a difficult challenge and uh yeah, we're we're up for it. I know yeah, we're we're up for it. I know yeah, we're we're up for it. I know there's there's a ton of work out there there's there's a ton of work out there there's there's a ton of work out there that we're uh following closely and uh that we're uh following closely and uh that we're uh following closely and uh especially on the exploitation side on especially on the exploitation side on especially on the exploitation side on the uh vulnerability discovery and the uh vulnerability discovery and the uh vulnerability discovery and defense or discovery primarily there's defense or discovery primarily there's defense or discovery primarily there's seems to be very little work or it's seems to be very little work or it's seems to be very little work or it's actually a nice big gap for us to actually a nice big gap for us to actually a nice big gap for us to explore but uh you know we have a ton of explore but uh you know we have a ton of explore but uh you know we have a ton of people at rand looking at the people at rand looking at the people at rand looking at the exploitation side right now um so we exploitation side right now um so we exploitation side right now um so we don't want to overlap with those don't want to overlap with those don't want to overlap with those projects and focus more on uh you know projects and focus more on uh you know projects and focus more on uh you know the how vulnerabilities fit into this the how vulnerabilities fit into this the how vulnerabilities fit into this and uh and really uh narrow down on that and uh and really uh narrow down on that and uh and really uh narrow down on that cuz uh I think that's we get the most cuz uh I think that's we get the most cuz uh I think that's we get the most bang for our buck there. But yeah, it's bang for our buck there. But yeah, it's bang for our buck there. But yeah, it's Do you have anything on that, D? All Do you have anything on that, D? All Do you have anything on that, D? All right, and with that uh let's give our right, and with that uh let's give our right, and with that uh let's give our uh presenters one more round of uh presenters one more round of uh presenters one more round of applause.