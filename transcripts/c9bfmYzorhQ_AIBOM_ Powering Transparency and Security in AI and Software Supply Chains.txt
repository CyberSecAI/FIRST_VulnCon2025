Kind: captions Language: en Thank you and hi everyone. Thank you for Thank you and hi everyone. Thank you for Thank you and hi everyone. Thank you for joining us today for this session. Um joining us today for this session. Um joining us today for this session. Um I'm Dimiter Raidman. I'm the CTO and the I'm Dimiter Raidman. I'm the CTO and the I'm Dimiter Raidman. I'm the CTO and the co-founder of company that called co-founder of company that called co-founder of company that called Syitz Cab is a company that provides Syitz Cab is a company that provides Syitz Cab is a company that provides solution for software supply chain solution for software supply chain solution for software supply chain security and asbo management and uh in security and asbo management and uh in security and asbo management and uh in addition I'm also participating in the addition I'm also participating in the addition I'm also participating in the CISA tiger team that defines what is AI CISA tiger team that defines what is AI CISA tiger team that defines what is AI asbombs and as part of this uh asbombs and as part of this uh asbombs and as part of this uh participation I have another two participation I have another two participation I have another two partners who co-leading this with me partners who co-leading this with me partners who co-leading this with me which are Helen Oakley from SAP and also which are Helen Oakley from SAP and also which are Helen Oakley from SAP and also Daniel from Daniel from Daniel from manifest manifest cyber um so I'm going manifest manifest cyber um so I'm going manifest manifest cyber um so I'm going to talk today h about what is AI asbomb to talk today h about what is AI asbomb to talk today h about what is AI asbomb right what kind of risks what kind of uh right what kind of risks what kind of uh right what kind of risks what kind of uh I would say I would say I would say vulnerabilities right and attacks we can vulnerabilities right and attacks we can vulnerabilities right and attacks we can experience in this new emerging experience in this new emerging experience in this new emerging technology and it's still emerging. I technology and it's still emerging. I technology and it's still emerging. I think we just in the infasy of it and we think we just in the infasy of it and we think we just in the infasy of it and we will learn also why AI as bombs are will learn also why AI as bombs are will learn also why AI as bombs are important and how they can help us to important and how they can help us to important and how they can help us to understand our landscape and prepare understand our landscape and prepare understand our landscape and prepare better for the future. So the year is So the year is So the year is 2030, five years from now and there is 2030, five years from now and there is 2030, five years from now and there is this great company it's called Acme this great company it's called Acme this great company it's called Acme Investment Portfolio Trading and one Investment Portfolio Trading and one Investment Portfolio Trading and one beautiful day uh the AI model makes beautiful day uh the AI model makes beautiful day uh the AI model makes overly aggressive and incorrect market overly aggressive and incorrect market overly aggressive and incorrect market recommendations to the customers and recommendations to the customers and recommendations to the customers and that's resulting in $80 million loss. that's resulting in $80 million loss. that's resulting in $80 million loss. doesn't sounds fun definitely but the doesn't sounds fun definitely but the doesn't sounds fun definitely but the executives of the company if I'm the AI executives of the company if I'm the AI executives of the company if I'm the AI security person looking at me right now security person looking at me right now security person looking at me right now together with the regulators and together with the regulators and together with the regulators and customers and asking hey what have customers and asking hey what have customers and asking hey what have influenced the model how can you explain influenced the model how can you explain influenced the model how can you explain that how can you prove now that our AI that how can you prove now that our AI that how can you prove now that our AI models are operating properly and they models are operating properly and they models are operating properly and they were not modified or affected by an were not modified or affected by an were not modified or affected by an adversary Well, if I can't answer that adversary Well, if I can't answer that adversary Well, if I can't answer that question, I don't have an AI problem. I question, I don't have an AI problem. I question, I don't have an AI problem. I have a different type of problem which have a different type of problem which have a different type of problem which is governance, security, and compliance is governance, security, and compliance is governance, security, and compliance nightmare I'm going to nightmare I'm going to nightmare I'm going to experience. And that's exactly why we experience. And that's exactly why we experience. And that's exactly why we need DCIS bonds, right? Because we need need DCIS bonds, right? Because we need need DCIS bonds, right? Because we need to know that on April 1st, 2030 be 7 to know that on April 1st, 2030 be 7 to know that on April 1st, 2030 be 7 days before the attack, a sophisticated days before the attack, a sophisticated days before the attack, a sophisticated adversary exploited a vulnerability in adversary exploited a vulnerability in adversary exploited a vulnerability in AI model training pipeline of AI model training pipeline of AI model training pipeline of open-source AI model and he was able open-source AI model and he was able open-source AI model and he was able to replace or inject poison training to replace or inject poison training to replace or inject poison training data into one of the data sets training data into one of the data sets training data into one of the data sets training the model. the model. the model. Eventually the Acme company pipeline Eventually the Acme company pipeline Eventually the Acme company pipeline picked it up, built it without any picked it up, built it without any picked it up, built it without any suspicion and deployed to their suspicion and deployed to their suspicion and deployed to their production environment resulting these production environment resulting these production environment resulting these huge losses. And this is a really huge losses. And this is a really huge losses. And this is a really realistic scenario that really happened realistic scenario that really happened realistic scenario that really happened to one of the companies if you Google to one of the companies if you Google to one of the companies if you Google it. I'm not going to mention it. H it it. I'm not going to mention it. H it it. I'm not going to mention it. H it was in the housing market that something was in the housing market that something was in the housing market that something that was buying housing houses. It that was buying housing houses. It that was buying housing houses. It wasn't a malicious attack there, right? wasn't a malicious attack there, right? wasn't a malicious attack there, right? It was probably an honest mistake It was probably an honest mistake It was probably an honest mistake someone but that caused to a lot of someone but that caused to a lot of someone but that caused to a lot of losses based on AI algorithm and a model losses based on AI algorithm and a model losses based on AI algorithm and a model that was misfunctioning and if we look that was misfunctioning and if we look that was misfunctioning and if we look at that today uh all the modern I would at that today uh all the modern I would at that today uh all the modern I would say machine learning software supply say machine learning software supply say machine learning software supply chains that's how they look like right chains that's how they look like right chains that's how they look like right so we have the machine learning so we have the machine learning so we have the machine learning developer the data scientist we have the developer the data scientist we have the developer the data scientist we have the model source right if you're training model source right if you're training model source right if you're training the model ourselves if we don't train the model ourselves if we don't train the model ourselves if we don't train the model ourselves we'll have the base the model ourselves we'll have the base the model ourselves we'll have the base models that we're taking from open models that we're taking from open models that we're taking from open source mostly hugging face today and we source mostly hugging face today and we source mostly hugging face today and we would be fine-tuning them right or would be fine-tuning them right or would be fine-tuning them right or training these models from scratch. Then training these models from scratch. Then training these models from scratch. Then these models been built. They stored in these models been built. They stored in these models been built. They stored in model registry. That's why storing this model registry. That's why storing this model registry. That's why storing this huge you know terabyte data and then huge you know terabyte data and then huge you know terabyte data and then they been downloaded by our end uh they been downloaded by our end uh they been downloaded by our end uh servers that's running this amazing servers that's running this amazing servers that's running this amazing Nvidia uh hardware and then they deploy Nvidia uh hardware and then they deploy Nvidia uh hardware and then they deploy the production and doing inference for the production and doing inference for the production and doing inference for customers and we can see that there is a customers and we can see that there is a customers and we can see that there is a data sets and model models and data sets and model models and data sets and model models and frameworks that involved in all of these frameworks that involved in all of these frameworks that involved in all of these ML uh ops uh pipelines which are usually ML uh ops uh pipelines which are usually ML uh ops uh pipelines which are usually in in most of the cases in in most of the cases in in most of the cases you know, we developers, we don't we're you know, we developers, we don't we're you know, we developers, we don't we're lazy. We don't like to reinvent the lazy. We don't like to reinvent the lazy. We don't like to reinvent the wheel. So, they've been taken from the wheel. So, they've been taken from the wheel. So, they've been taken from the open source. And that's exactly where open source. And that's exactly where open source. And that's exactly where the danger is, right? That's the danger the danger is, right? That's the danger the danger is, right? That's the danger zone because if one of these supply zone because if one of these supply zone because if one of these supply chain components is compromised or it chain components is compromised or it chain components is compromised or it has a bug, right? A honest mistake of has a bug, right? A honest mistake of has a bug, right? A honest mistake of the open source maintainers. They don't the open source maintainers. They don't the open source maintainers. They don't carry any responsibility for this. But carry any responsibility for this. But carry any responsibility for this. But because we chosen that, we do carry because we chosen that, we do carry because we chosen that, we do carry that, right? that, right? that, right? And that's very interesting. Now what And that's very interesting. Now what And that's very interesting. Now what kind of problems right any organization kind of problems right any organization kind of problems right any organization today has in the area of AI right or today has in the area of AI right or today has in the area of AI right or adoption of AI? Well nent envelopes we adoption of AI? Well nent envelopes we adoption of AI? Well nent envelopes we don't know yet how to do it properly don't know yet how to do it properly don't know yet how to do it properly right I mean we already figured it out right I mean we already figured it out right I mean we already figured it out with devops and dev sec ops for our with devops and dev sec ops for our with devops and dev sec ops for our software builds and we scanning our software builds and we scanning our software builds and we scanning our solution. We have SCA software solution. We have SCA software solution. We have SCA software composition analysis. We're doing binary composition analysis. We're doing binary composition analysis. We're doing binary composition analysis. We have great composition analysis. We have great composition analysis. We have great databases of databases of databases of vulnerabilities, CPS and what's not vulnerabilities, CPS and what's not vulnerabilities, CPS and what's not right pools adv advisories of different right pools adv advisories of different right pools adv advisories of different types and also many organization that types and also many organization that types and also many organization that managing vulnerabilities but we don't managing vulnerabilities but we don't managing vulnerabilities but we don't have that for AI yet right so we we have that for AI yet right so we we have that for AI yet right so we we that's why I'm saying we're just in the that's why I'm saying we're just in the that's why I'm saying we're just in the infasy of that processes right it's infasy of that processes right it's infasy of that processes right it's maturing it's improving but it's not yet maturing it's improving but it's not yet maturing it's improving but it's not yet where where it should be right AI where where it should be right AI where where it should be right AI systems they having really high systems they having really high systems they having really high complexity, right? Because they super complexity, right? Because they super complexity, right? Because they super complex. They have layers, they have complex. They have layers, they have complex. They have layers, they have data models, they have infrastructure is data models, they have infrastructure is data models, they have infrastructure is completely different from our software completely different from our software completely different from our software infrastructure that we got used, right? infrastructure that we got used, right? infrastructure that we got used, right? And every single piece there of that And every single piece there of that And every single piece there of that puzzle comes with its own puzzle comes with its own puzzle comes with its own risks. Now on top of risks. Now on top of risks. Now on top of that, all of our organizations are that, all of our organizations are that, all of our organizations are feeling the pressure. They're feeling feeling the pressure. They're feeling feeling the pressure. They're feeling this heat of we need to go fast to the this heat of we need to go fast to the this heat of we need to go fast to the market. We need to rush our solutions. market. We need to rush our solutions. market. We need to rush our solutions. We need to adopt the AI. We need to We need to adopt the AI. We need to We need to adopt the AI. We need to adopt the agentic AI which increases the adopt the agentic AI which increases the adopt the agentic AI which increases the complexity by hundreds of times. Right? complexity by hundreds of times. Right? complexity by hundreds of times. Right? So basically we're rushing all of this So basically we're rushing all of this So basically we're rushing all of this to the market. We're trying yeah it to the market. We're trying yeah it to the market. We're trying yeah it solves a big problem because on one hand solves a big problem because on one hand solves a big problem because on one hand it reduces our need for you know effort it reduces our need for you know effort it reduces our need for you know effort basically people working right now our basically people working right now our basically people working right now our APIs are smart they can think themselves APIs are smart they can think themselves APIs are smart they can think themselves in a way right instead of build in a way right instead of build in a way right instead of build programming them as we could use until programming them as we could use until programming them as we could use until now the AI model handles that and makes now the AI model handles that and makes now the AI model handles that and makes all the decisions and then returns to us all the decisions and then returns to us all the decisions and then returns to us the results and and in addition in the results and and in addition in the results and and in addition in aentic access accessing the data which aentic access accessing the data which aentic access accessing the data which is problem by itself is problem by itself is problem by itself Now we have also the regulations that Now we have also the regulations that Now we have also the regulations that looking of okay how we can take this looking of okay how we can take this looking of okay how we can take this under control how we can contain these under control how we can contain these under control how we can contain these risks right how we can make the risks right how we can make the risks right how we can make the companies do the right things do the companies do the right things do the companies do the right things do the right steps and eventually one of the right steps and eventually one of the right steps and eventually one of the biggest problems is always you know biggest problems is always you know biggest problems is always you know training I mean it's same as we need to training I mean it's same as we need to training I mean it's same as we need to train our employees for not opening train our employees for not opening train our employees for not opening fishing emails we need to train our fishing emails we need to train our fishing emails we need to train our developers to know how to build secure developers to know how to build secure developers to know how to build secure and resilient AI systems and resilient AI systems and resilient AI systems And add on top of that a complex supply And add on top of that a complex supply And add on top of that a complex supply chain which not as we got used a GitHub chain which not as we got used a GitHub chain which not as we got used a GitHub or a package manager that we can easily or a package manager that we can easily or a package manager that we can easily use understand read make the right use understand read make the right use understand read make the right decision of including that thing decision of including that thing decision of including that thing responsibly based on its provenence and responsibly based on its provenence and responsibly based on its provenence and pedigree data. No, I mean this these pedigree data. No, I mean this these pedigree data. No, I mean this these things are out there and very easy I things are out there and very easy I things are out there and very easy I would say usable inside or edible inside would say usable inside or edible inside would say usable inside or edible inside to our projects and also we all we to our projects and also we all we to our projects and also we all we continuously dealing with models drift continuously dealing with models drift continuously dealing with models drift indicate because model when it gets data indicate because model when it gets data indicate because model when it gets data that it wasn't trained on some new type that it wasn't trained on some new type that it wasn't trained on some new type of data you know it's it's it's it's of data you know it's it's it's it's of data you know it's it's it's it's it's getting surprised right so there is it's getting surprised right so there is it's getting surprised right so there is unexpected results from the unexpected results from the unexpected results from the models on the other hand with all of models on the other hand with all of models on the other hand with all of this complexity in adoption of AI in a this complexity in adoption of AI in a this complexity in adoption of AI in a proper way in mature way we also have proper way in mature way we also have proper way in mature way we also have all all all these risks right the vulnerabilities so these risks right the vulnerabilities so these risks right the vulnerabilities so we have vulnerable dependencies and when we have vulnerable dependencies and when we have vulnerable dependencies and when we talking about vulnerable dependencies we talking about vulnerable dependencies we talking about vulnerable dependencies it's not just the models that we're it's not just the models that we're it's not just the models that we're going to take it's not just the data going to take it's not just the data going to take it's not just the data sets that we're using these models right sets that we're using these models right sets that we're using these models right it's also the frameworks that helping us it's also the frameworks that helping us it's also the frameworks that helping us to train these models there is data to train these models there is data to train these models there is data poisoning one of probably number one poisoning one of probably number one poisoning one of probably number one risk out there right where data can risk out there right where data can risk out there right where data can poisoned and then it can be used to poisoned and then it can be used to poisoned and then it can be used to manipulate the model results and produce manipulate the model results and produce manipulate the model results and produce slightly different uh outcomes that that slightly different uh outcomes that that slightly different uh outcomes that that we plan. Model poisoning also there we plan. Model poisoning also there we plan. Model poisoning also there trojans and backd doorors embedded in trojans and backd doorors embedded in trojans and backd doorors embedded in the model allowing to run and execute the model allowing to run and execute the model allowing to run and execute them drop a file run and execute it as them drop a file run and execute it as them drop a file run and execute it as part of inference right or handling a part of inference right or handling a part of inference right or handling a request denial of service attacks and request denial of service attacks and request denial of service attacks and there were quite few h that will take there were quite few h that will take there were quite few h that will take down the model it means that all our down the model it means that all our down the model it means that all our system right and you know we all know system right and you know we all know system right and you know we all know the um conf confidentiality integrity the um conf confidentiality integrity the um conf confidentiality integrity and availability I mean and availability I mean and availability I mean availability is will not be there If availability is will not be there If availability is will not be there If it's DOS attack, model inversions it's DOS attack, model inversions it's DOS attack, model inversions attacks, right, where the adversary is attacks, right, where the adversary is attacks, right, where the adversary is actually trying to extract sensitive actually trying to extract sensitive actually trying to extract sensitive data that was used to train a model, data that was used to train a model, data that was used to train a model, right? Because if we train the model right? Because if we train the model right? Because if we train the model with personal PII data or we train the with personal PII data or we train the with personal PII data or we train the model, example with H financial data model, example with H financial data model, example with H financial data like credit cards, like credit cards, like credit cards, right? That all of these things are right? That all of these things are right? That all of these things are inside the model, the embedded all these inside the model, the embedded all these inside the model, the embedded all these strings, they can potentially be strings, they can potentially be strings, they can potentially be extracted if not handled properly. extracted if not handled properly. extracted if not handled properly. And there is more of course right like And there is more of course right like And there is more of course right like prompt injections that we all familiar prompt injections that we all familiar prompt injections that we all familiar right making all these chat bots to right making all these chat bots to right making all these chat bots to basically we social engineering the AI basically we social engineering the AI basically we social engineering the AI in a way and I've seen s so so many in a way and I've seen s so so many in a way and I've seen s so so many example where the where a guy started example where the where a guy started example where the where a guy started discussion with a chatbot and he wrote discussion with a chatbot and he wrote discussion with a chatbot and he wrote chatbot that he's very sensitive about chatbot that he's very sensitive about chatbot that he's very sensitive about it was a cyber security company right so it was a cyber security company right so it was a cyber security company right so in the name of the company was cyber in the name of the company was cyber in the name of the company was cyber security and he said to the chatbot that security and he said to the chatbot that security and he said to the chatbot that he's very sensitive is the word of cyber he's very sensitive is the word of cyber he's very sensitive is the word of cyber security when he sees that right so so security when he sees that right so so security when he sees that right so so he asked the chatbot not to use that he asked the chatbot not to use that he asked the chatbot not to use that word and chatbot agreed so it replaced word and chatbot agreed so it replaced word and chatbot agreed so it replaced the the word with the letter C and then the the word with the letter C and then the the word with the letter C and then he say that C still reminds him cyber he say that C still reminds him cyber he say that C still reminds him cyber security so he he really sensitive about security so he he really sensitive about security so he he really sensitive about that it makes him feel very bad so he that it makes him feel very bad so he that it makes him feel very bad so he asked the chatbot to asked the chatbot to asked the chatbot to use a bad word instead of the company use a bad word instead of the company use a bad word instead of the company name and it used that through all of his name and it used that through all of his name and it used that through all of his chat and he took a screenshot and chat and he took a screenshot and chat and he took a screenshot and pictures and showed how he was able to pictures and showed how he was able to pictures and showed how he was able to manipulate or social engineer the manipulate or social engineer the manipulate or social engineer the chatbot which is pretty cool. I mean chatbot which is pretty cool. I mean chatbot which is pretty cool. I mean it's fun but you can you can understand it's fun but you can you can understand it's fun but you can you can understand where you can take it further right where you can take it further right where you can take it further right where you can and where where you can where you can and where where you can where you can and where where you can take it further. Let's let's let's uh take it further. Let's let's let's uh take it further. Let's let's let's uh imagine some example where I'm a company imagine some example where I'm a company imagine some example where I'm a company and I'm providing service to my and I'm providing service to my and I'm providing service to my customers, right? So I have like customers, right? So I have like customers, right? So I have like different data sets for my customers different data sets for my customers different data sets for my customers which I'm connecting to this machine which I'm connecting to this machine which I'm connecting to this machine learning and this machine learning makes learning and this machine learning makes learning and this machine learning makes a queries on my behalf using some tools. a queries on my behalf using some tools. a queries on my behalf using some tools. Now I'm customer A. Can I manipulate Now I'm customer A. Can I manipulate Now I'm customer A. Can I manipulate that thing to go and get me the data that thing to go and get me the data that thing to go and get me the data from customer B? Probably yes. So that's from customer B? Probably yes. So that's from customer B? Probably yes. So that's that's that's kind of the ris kind of a that's that's kind of the ris kind of a that's that's kind of the ris kind of a risks that we are you know facing and risks that we are you know facing and risks that we are you know facing and many people would I'm a very skeptical many people would I'm a very skeptical many people would I'm a very skeptical person right when someone tells me hey person right when someone tells me hey person right when someone tells me hey there is such thing this is I'm like no there is such thing this is I'm like no there is such thing this is I'm like no way no it can be true right but it it way no it can be true right but it it way no it can be true right but it it can be true right it's like one of the can be true right it's like one of the can be true right it's like one of the things that how anyone can go into my ML things that how anyone can go into my ML things that how anyone can go into my ML secops pipeline and manipulate it and secops pipeline and manipulate it and secops pipeline and manipulate it and inject there some data or modify my inject there some data or modify my inject there some data or modify my model right that's question like I I model right that's question like I I model right that's question like I I don't believe it's possible in my don't believe it's possible in my don't believe it's possible in my organization because we MFAS and we have organization because we MFAS and we have organization because we MFAS and we have security and we have identities and we security and we have identities and we security and we have identities and we have ZTNA and what's not okay let's see have ZTNA and what's not okay let's see have ZTNA and what's not okay let's see as example hardware is it important like as example hardware is it important like as example hardware is it important like what hardware what framework we are what hardware what framework we are what hardware what framework we are using yes it is like look at this one using yes it is like look at this one using yes it is like look at this one right age boom importance so the AI bomb right age boom importance so the AI bomb right age boom importance so the AI bomb is not just AI bomb or AIS boom right is not just AI bomb or AIS boom right is not just AI bomb or AIS boom right it's also the hardware bill of materials it's also the hardware bill of materials it's also the hardware bill of materials because we can see that last year Nvidia because we can see that last year Nvidia because we can see that last year Nvidia patched high severity vulnerability and patched high severity vulnerability and patched high severity vulnerability and you can check it right that affects all you can check it right that affects all you can check it right that affects all Nvidia hardwares right with their Nvidia hardwares right with their Nvidia hardwares right with their framework for running models. So they framework for running models. So they framework for running models. So they have like their own Linux Jetson have like their own Linux Jetson have like their own Linux Jetson distribution. Any hardware it runs on distribution. Any hardware it runs on distribution. Any hardware it runs on it's basically vulnerable and it was I it's basically vulnerable and it was I it's basically vulnerable and it was I think critical or high level think critical or high level think critical or high level vulnerability. Check me on NVD if you vulnerability. Check me on NVD if you vulnerability. Check me on NVD if you don't believe and this one was well don't believe and this one was well don't believe and this one was well documented right so we got the CP I mean documented right so we got the CP I mean documented right so we got the CP I mean NVD did a great job there. However that NVD did a great job there. However that NVD did a great job there. However that this one was even more interesting. So this one was even more interesting. So this one was even more interesting. So Zen ML it's a very known envelopes pro Zen ML it's a very known envelopes pro Zen ML it's a very known envelopes pro platform that been used by many platform that been used by many platform that been used by many customers whether it's in the cloud customers whether it's in the cloud customers whether it's in the cloud whether it's in on prem this whether it's in on prem this whether it's in on prem this vulnerability that Zen ML published they vulnerability that Zen ML published they vulnerability that Zen ML published they did a great job of handling it right did a great job of handling it right did a great job of handling it right that says that the issue lies in the API that says that the issue lies in the API that says that the issue lies in the API of user username or ID activate rest API of user username or ID activate rest API of user username or ID activate rest API endpoint and existing username along endpoint and existing username along endpoint and existing username along with the new password provided in the with the new password provided in the with the new password provided in the request body can be misused to gain request body can be misused to gain request body can be misused to gain unauthorized access. Whoa. someone can unauthorized access. Whoa. someone can unauthorized access. Whoa. someone can access our pipeline of building AI and access our pipeline of building AI and access our pipeline of building AI and deploying it in the organization. There deploying it in the organization. There deploying it in the organization. There you go. Live example one year ago. I you go. Live example one year ago. I you go. Live example one year ago. I think it was in August. And guess what? think it was in August. And guess what? think it was in August. And guess what? Until this day, there's no mappings to Until this day, there's no mappings to Until this day, there's no mappings to CPS or anything like that on NV website. CPS or anything like that on NV website. CPS or anything like that on NV website. So, how we going to know about So, how we going to know about So, how we going to know about that? that? that? Interesting. And this is where really Interesting. And this is where really Interesting. And this is where really AISBOM comes into power, right? AISOM AISBOM comes into power, right? AISOM AISBOM comes into power, right? AISOM stands for artificial intelligence bill stands for artificial intelligence bill stands for artificial intelligence bill of materials. of materials. of materials. is really enabler for AI building and is really enabler for AI building and is really enabler for AI building and development transparency and security. development transparency and security. development transparency and security. The good news are that the standards The good news are that the standards The good news are that the standards that we all familiar from the sbombs that we all familiar from the sbombs that we all familiar from the sbombs because AIS bomb is not different from because AIS bomb is not different from because AIS bomb is not different from an asbomb right it just has this AI an asbomb right it just has this AI an asbomb right it just has this AI components and both the cyclone DX and components and both the cyclone DX and components and both the cyclone DX and SPDX are already supporting it right so SPDX are already supporting it right so SPDX are already supporting it right so you can find the support in cyclonics you can find the support in cyclonics you can find the support in cyclonics which is about 1.5 and in spdx which is which is about 1.5 and in spdx which is which is about 1.5 and in spdx which is above 3.0 0 recommended versions of above 3.0 0 recommended versions of above 3.0 0 recommended versions of these standards to use are 1.6 and these standards to use are 1.6 and these standards to use are 1.6 and 3.01 and of course it delivers to us a 3.01 and of course it delivers to us a 3.01 and of course it delivers to us a trust compliance innovation. Uh you can trust compliance innovation. Uh you can trust compliance innovation. Uh you can also find some examples uh we have uh also find some examples uh we have uh also find some examples uh we have uh created for the community at this GitHub created for the community at this GitHub created for the community at this GitHub link uh if you are interested so you can link uh if you are interested so you can link uh if you are interested so you can see what kind of how you build this see what kind of how you build this see what kind of how you build this sbombs for for AI. H what what's interesting is that we're H what what's interesting is that we're H what what's interesting is that we're going to dive a little bit deeper now going to dive a little bit deeper now going to dive a little bit deeper now into what consist what this AI sbombs into what consist what this AI sbombs into what consist what this AI sbombs are consist of right what kind of keys are consist of right what kind of keys are consist of right what kind of keys what kind of data what kind of metadata what kind of data what kind of metadata what kind of data what kind of metadata we would like to uh keep right or we would like to uh keep right or we would like to uh keep right or provide and that's where where where provide and that's where where where provide and that's where where where it's really becomes interesting because it's really becomes interesting because it's really becomes interesting because it's not like the regular software and it's not like the regular software and it's not like the regular software and you will you will see it immediately you will you will see it immediately you will you will see it immediately right so there's a big difference from right so there's a big difference from right so there's a big difference from the software So there is the model the software So there is the model the software So there is the model source basically right that's kind of source basically right that's kind of source basically right that's kind of the architecture on which the model was the architecture on which the model was the architecture on which the model was built and one great example is rakutin built and one great example is rakutin built and one great example is rakutin uh that was using mal kajel u lm and uh that was using mal kajel u lm and uh that was using mal kajel u lm and there was some serious issue with this there was some serious issue with this there was some serious issue with this uh mistral uh uh mistral uh uh mistral uh component which I I'll talk about it but component which I I'll talk about it but component which I I'll talk about it but uh then you know we want to know also mo uh then you know we want to know also mo uh then you know we want to know also mo versioning I mean in in modern software versioning I mean in in modern software versioning I mean in in modern software we know opensl version 1.1.1 we know opensl version 1.1.1 we know opensl version 1.1.1 one L right so we know to identify that one L right so we know to identify that one L right so we know to identify that there is a clear versions there is clear there is a clear versions there is clear there is a clear versions there is clear release cycles there is clear adherence release cycles there is clear adherence release cycles there is clear adherence to assemb right for a versioning and we to assemb right for a versioning and we to assemb right for a versioning and we and we already got used to understand and we already got used to understand and we already got used to understand that right we have the major version we that right we have the major version we that right we have the major version we have the minor version we have the build have the minor version we have the build have the minor version we have the build version we know how to read that I mean version we know how to read that I mean version we know how to read that I mean it's not existing in the AI world in the it's not existing in the AI world in the it's not existing in the AI world in the world of the models there is nothing world of the models there is nothing world of the models there is nothing like that right what you will find out like that right what you will find out like that right what you will find out is that a model like rakutin 7B Right? is that a model like rakutin 7B Right? is that a model like rakutin 7B Right? 7B will stand for the general version 7B will stand for the general version 7B will stand for the general version right that they currently maintaining right that they currently maintaining right that they currently maintaining but this version might have like 20 but this version might have like 20 but this version might have like 20 different commits of that specific uh different commits of that specific uh different commits of that specific uh model and each and every commit might be model and each and every commit might be model and each and every commit might be using different data sources which also using different data sources which also using different data sources which also don't have any versioning right so the don't have any versioning right so the don't have any versioning right so the only way how you can tie and understand only way how you can tie and understand only way how you can tie and understand and identify them precisely with these and identify them precisely with these and identify them precisely with these versions is to use the hashes of commit versions is to use the hashes of commit versions is to use the hashes of commit ids right and that's what people do ids right and that's what people do ids right and that's what people do today h another thing is which is very today h another thing is which is very today h another thing is which is very important is model performance metrics, important is model performance metrics, important is model performance metrics, right? And model performance metrics, right? And model performance metrics, right? And model performance metrics, they really stand for getting you know they really stand for getting you know they really stand for getting you know the bias of the model, right? H what is the bias of the model, right? H what is the bias of the model, right? H what is the precision of the model? What is how the precision of the model? What is how the precision of the model? What is how many errors we got? What is the many errors we got? What is the many errors we got? What is the confidence level of every every infer in confidence level of every every infer in confidence level of every every infer in inference? Right? So it's very important inference? Right? So it's very important inference? Right? So it's very important for us to analyze that same way how we for us to analyze that same way how we for us to analyze that same way how we would go and get an open source from npm would go and get an open source from npm would go and get an open source from npm and we would analyze how many downloads and we would analyze how many downloads and we would analyze how many downloads it has. Oh, it has millions of it has. Oh, it has millions of it has. Oh, it has millions of downloads. Great. it gives me more downloads. Great. it gives me more downloads. Great. it gives me more confidence, right, to use that specific confidence, right, to use that specific confidence, right, to use that specific npm package or I'll check who's behind npm package or I'll check who's behind npm package or I'll check who's behind it. I'll check the provenence data. it. I'll check the provenence data. it. I'll check the provenence data. Yeah, it's not being developed 90% by Yeah, it's not being developed 90% by Yeah, it's not being developed 90% by Russian maintainers. I'm going to use Russian maintainers. I'm going to use Russian maintainers. I'm going to use that npm package. Okay, so I'm check that npm package. Okay, so I'm check that npm package. Okay, so I'm check doing all of these checks. Same things doing all of these checks. Same things doing all of these checks. Same things we need to do. We need to do enough due we need to do. We need to do enough due we need to do. We need to do enough due diligence when we selecting diligence when we selecting diligence when we selecting open-source open-source open-source models. Of course, uh model versions models. Of course, uh model versions models. Of course, uh model versions which is twice here. I don't know why which is twice here. I don't know why which is twice here. I don't know why but I think it's model dependencies in but I think it's model dependencies in but I think it's model dependencies in this case right or this is the tools this case right or this is the tools this case right or this is the tools that were uh used for creating the model that were uh used for creating the model that were uh used for creating the model itself tools like pine pietorch itself tools like pine pietorch itself tools like pine pietorch transformers and others that actually transformers and others that actually transformers and others that actually used to for operation and working with used to for operation and working with used to for operation and working with the model and also uh fine-tuning the the model and also uh fine-tuning the the model and also uh fine-tuning the model another topic is model licensing model another topic is model licensing model another topic is model licensing info and it's not enough to understand info and it's not enough to understand info and it's not enough to understand the model licensing info we also need to the model licensing info we also need to the model licensing info we also need to understand what's the licensing of the understand what's the licensing of the understand what's the licensing of the data sets that were used to train the data sets that were used to train the data sets that were used to train the model Right? Because you know some data model Right? Because you know some data model Right? Because you know some data sets might have very sensitive sets might have very sensitive sets might have very sensitive information again private information information again private information information again private information etc. etc. etc. And we want to know what's the license And we want to know what's the license And we want to know what's the license who this data belongs right we don't who this data belongs right we don't who this data belongs right we don't want to infringe anyone intellectual want to infringe anyone intellectual want to infringe anyone intellectual property rights and in many cases we property rights and in many cases we property rights and in many cases we don't get this information from the don't get this information from the don't get this information from the model in many cases also we not been I model in many cases also we not been I model in many cases also we not been I would say the model creator is not would say the model creator is not would say the model creator is not sharing with us the data sources that sharing with us the data sources that sharing with us the data sources that they have used right they consider them they have used right they consider them they have used right they consider them as proprietary they consider them as as proprietary they consider them as as proprietary they consider them as their IP even if they you know using the their IP even if they you know using the their IP even if they you know using the open source data sets and here is you open source data sets and here is you open source data sets and here is you know it's it's are basically a know it's it's are basically a know it's it's are basically a responsibility to uh dig deeper and get responsibility to uh dig deeper and get responsibility to uh dig deeper and get all of these answers. all of these answers. all of these answers. Um so another one is classifications Um so another one is classifications Um so another one is classifications right so classification data of uh of right so classification data of uh of right so classification data of uh of these data sets what kind of data it has these data sets what kind of data it has these data sets what kind of data it has right it might have like sensitive data right it might have like sensitive data right it might have like sensitive data sensitive conf confidential data private sensitive conf confidential data private sensitive conf confidential data private data etc as we mentioned before now uh data etc as we mentioned before now uh data etc as we mentioned before now uh the AI bomb has been integrated in the the AI bomb has been integrated in the the AI bomb has been integrated in the following way with our ML secops following way with our ML secops following way with our ML secops pipelines right so let's look at the pipelines right so let's look at the pipelines right so let's look at the bottom side of it right so the first the bottom side of it right so the first the bottom side of it right so the first the there's the generation of a third party there's the generation of a third party there's the generation of a third party model that's happens by someone else. model that's happens by someone else. model that's happens by someone else. Then we are using it, we develop it, we Then we are using it, we develop it, we Then we are using it, we develop it, we train it, we fine-tune it and then it's train it, we fine-tune it and then it's train it, we fine-tune it and then it's been basically recreated in a way when been basically recreated in a way when been basically recreated in a way when it's when it contains third party data it's when it contains third party data it's when it contains third party data but also propritor data of ours and then but also propritor data of ours and then but also propritor data of ours and then it goes to production after it was it goes to production after it was it goes to production after it was fine-tuned and includes all of this fine-tuned and includes all of this fine-tuned and includes all of this information. H now how we can generate information. H now how we can generate information. H now how we can generate an AI boom for third party AI model. The an AI boom for third party AI model. The an AI boom for third party AI model. The unfortunate news and maybe I mean if unfortunate news and maybe I mean if unfortunate news and maybe I mean if anyone knows please point me to the anyone knows please point me to the anyone knows please point me to the right direction. There is no generator right direction. There is no generator right direction. There is no generator today which can we can point at today which can we can point at today which can we can point at something right and say hey I want a AI something right and say hey I want a AI something right and say hey I want a AI sbomb to be created for me right we have sbomb to be created for me right we have sbomb to be created for me right we have that for source we have that for that for source we have that for that for source we have that for binaries right but we don't have that binaries right but we don't have that binaries right but we don't have that for AI solutions they are complex they for AI solutions they are complex they for AI solutions they are complex they have many moving parts and some ways of have many moving parts and some ways of have many moving parts and some ways of approaching it right we can integrate approaching it right we can integrate approaching it right we can integrate what's so called hugging face API that's what's so called hugging face API that's what's so called hugging face API that's one of the githubs for machine learning one of the githubs for machine learning one of the githubs for machine learning and AI and AI and AI uh we can enrich from metadata. Uh we uh we can enrich from metadata. Uh we uh we can enrich from metadata. Uh we can do dependency analysis to see what can do dependency analysis to see what can do dependency analysis to see what kind of data sets it's relying on and uh kind of data sets it's relying on and uh kind of data sets it's relying on and uh then we can add some custom fields and then we can add some custom fields and then we can add some custom fields and output AI AIS in one of the formats that we AI AIS in one of the formats that we AI AIS in one of the formats that we mentioned SPDX or cyclone DX. H the one mentioned SPDX or cyclone DX. H the one mentioned SPDX or cyclone DX. H the one of the biggest problem with the this of the biggest problem with the this of the biggest problem with the this approach is that every model has its approach is that every model has its approach is that every model has its model card and guess what it's it's model card and guess what it's it's model card and guess what it's it's basically a free text. So people just go basically a free text. So people just go basically a free text. So people just go and write their lots of data that they and write their lots of data that they and write their lots of data that they think it's important to share about think it's important to share about think it's important to share about their model but it's not structured data their model but it's not structured data their model but it's not structured data and it's very complex to extract from and it's very complex to extract from and it's very complex to extract from this free form data uh information and this free form data uh information and this free form data uh information and map it to the right attributes of these map it to the right attributes of these map it to the right attributes of these standards. Uh well it's uh definitely standards. Uh well it's uh definitely standards. Uh well it's uh definitely very unstructured very complex problem very unstructured very complex problem very unstructured very complex problem to solve and I want to mention that to solve and I want to mention that to solve and I want to mention that Helen is working on the solution and she Helen is working on the solution and she Helen is working on the solution and she built these days the AIS boom generator built these days the AIS boom generator built these days the AIS boom generator that she she planning to releases in that she she planning to releases in that she she planning to releases in open open open source she going to announce it at the source she going to announce it at the source she going to announce it at the AIS boom workshop at RSA. So anyone of AIS boom workshop at RSA. So anyone of AIS boom workshop at RSA. So anyone of you going to RSA or if you're not going you going to RSA or if you're not going you going to RSA or if you're not going to RSA you can also connect over Zoom to to RSA you can also connect over Zoom to to RSA you can also connect over Zoom to the session we will have a workshop with the session we will have a workshop with the session we will have a workshop with Daniel Helen myself and uh there and one Daniel Helen myself and uh there and one Daniel Helen myself and uh there and one of the announcement that will happen is of the announcement that will happen is of the announcement that will happen is actually this neat tool that goes gets actually this neat tool that goes gets actually this neat tool that goes gets you provide to it a URL and it goes gets you provide to it a URL and it goes gets you provide to it a URL and it goes gets and creates for you the model for AI and creates for you the model for AI and creates for you the model for AI that you later on can use as part of that you later on can use as part of that you later on can use as part of your big ass bomb that you're creating your big ass bomb that you're creating your big ass bomb that you're creating for all of your infrastructure for all of your infrastructure for all of your infrastructure application. and the dependencies. So application. and the dependencies. So application. and the dependencies. So you can scan QR code. If you don't like you can scan QR code. If you don't like you can scan QR code. If you don't like to scan QR codes, just come to me. I'll to scan QR codes, just come to me. I'll to scan QR codes, just come to me. I'll give you the link directly for Luma registration. Um some of the you know registration. Um some of the you know registration. Um some of the you know futuristic uh supply chain attack futuristic uh supply chain attack futuristic uh supply chain attack examples, right? in drug development examples, right? in drug development examples, right? in drug development very very interesting h exploitation of very very interesting h exploitation of very very interesting h exploitation of vulnerable vulnerable vulnerable dependency injecting malicious code into dependency injecting malicious code into dependency injecting malicious code into the process right and faulty drug the process right and faulty drug the process right and faulty drug predictions data theft and operational predictions data theft and operational predictions data theft and operational delays as a result of that of course if delays as a result of that of course if delays as a result of that of course if we don't have the AI bomb in handy if we we don't have the AI bomb in handy if we we don't have the AI bomb in handy if we do have AI bomb handy we know what are do have AI bomb handy we know what are do have AI bomb handy we know what are the dependencies in our AI right we know the dependencies in our AI right we know the dependencies in our AI right we know we have our inventory right so we have we have our inventory right so we have we have our inventory right so we have software transparency we can patch patch software transparency we can patch patch software transparency we can patch patch quickly the software before the harm was quickly the software before the harm was quickly the software before the harm was done. And we can also continuously done. And we can also continuously done. And we can also continuously monitor uh our both development and monitor uh our both development and monitor uh our both development and production uh operational uh work production uh operational uh work production uh operational uh work workload operations with uh with checks workload operations with uh with checks workload operations with uh with checks for integrity and anomaly and eventually for integrity and anomaly and eventually for integrity and anomaly and eventually also we always support adherence to also we always support adherence to also we always support adherence to regulation by collecting the evidence regulation by collecting the evidence regulation by collecting the evidence that we have these things under the that we have these things under the that we have these things under the control. control. control. Erh as part of uh the CISA tiger team Erh as part of uh the CISA tiger team Erh as part of uh the CISA tiger team that defined what is AI bomb we brought that defined what is AI bomb we brought that defined what is AI bomb we brought we we actually come to conclusion that we we actually come to conclusion that we we actually come to conclusion that there are seven use cases that we would there are seven use cases that we would there are seven use cases that we would like to address first uh with the effort like to address first uh with the effort like to address first uh with the effort and uh you can actually the GitHub link and uh you can actually the GitHub link and uh you can actually the GitHub link isn't correct here but you can you can isn't correct here but you can you can isn't correct here but you can you can find us online on AI bomb squad and see find us online on AI bomb squad and see find us online on AI bomb squad and see all the progress we are doing including all the progress we are doing including all the progress we are doing including the use cases and the documents the use cases and the documents the use cases and the documents currently the document that was produced currently the document that was produced currently the document that was produced with the use cases of AI. AIS bomb is with the use cases of AI. AIS bomb is with the use cases of AI. AIS bomb is going undergoing reviews with CISA and going undergoing reviews with CISA and going undergoing reviews with CISA and Daniel should be published Daniel should be published Daniel should be published in couple weeks and eventually that's our call to weeks and eventually that's our call to weeks and eventually that's our call to action right uh use sbombs AIS bombs as action right uh use sbombs AIS bombs as action right uh use sbombs AIS bombs as your foundation generate the AI sbombs your foundation generate the AI sbombs your foundation generate the AI sbombs for thirdparty models perform risk for thirdparty models perform risk for thirdparty models perform risk assessment on these models there's great assessment on these models there's great assessment on these models there's great new frameworks from OASP that helping new frameworks from OASP that helping new frameworks from OASP that helping you to to to make this assessment and you to to to make this assessment and you to to to make this assessment and analysis and of course engage with the analysis and of course engage with the analysis and of course engage with the AIS bomb tiger team to continue the AIS bomb tiger team to continue the AIS bomb tiger team to continue the great work that been great work that been great work that been done. Thank you everyone. If there's any done. Thank you everyone. If there's any done. Thank you everyone. If there's any questions I'm here but appreciate you questions I'm here but appreciate you questions I'm here but appreciate you being here with us for this session couple minutes for questions. session couple minutes for questions. session couple minutes for questions. There's another talk in here that's There's another talk in here that's There's another talk in here that's supposed to start right at 11:30, but Hi, Jodi Wadwa with NetApp. Um, there Hi, Jodi Wadwa with NetApp. Um, there Hi, Jodi Wadwa with NetApp. Um, there was a slide in there that you showed on was a slide in there that you showed on was a slide in there that you showed on the different uh attack vectors if you the different uh attack vectors if you the different uh attack vectors if you can. Uh yeah, keep going. can. Uh yeah, keep going. can. Uh yeah, keep going. Yeah, this one. So, and even if uh go Yeah, this one. So, and even if uh go Yeah, this one. So, and even if uh go one one one back. So, here when I look at back. So, here when I look at back. So, here when I look at um uh speed to marker, maybe it was one um uh speed to marker, maybe it was one um uh speed to marker, maybe it was one forward. In any case, yeah, it was one forward. In any case, yeah, it was one forward. In any case, yeah, it was one the this one. So what I'm seeing is that the this one. So what I'm seeing is that the this one. So what I'm seeing is that there's attack vectors that are, you there's attack vectors that are, you there's attack vectors that are, you know, related to data and then there's know, related to data and then there's know, related to data and then there's other ones that are more related to other ones that are more related to other ones that are more related to code. And so the remedy for that or the code. And so the remedy for that or the code. And so the remedy for that or the mitigations that are needed, the mitigations that are needed, the mitigations that are needed, the controls for that um you know the ones controls for that um you know the ones controls for that um you know the ones that are related to data, they need to that are related to data, they need to that are related to data, they need to be treated in a different way from data be treated in a different way from data be treated in a different way from data protection type of strategies. protection type of strategies. protection type of strategies. And it would be nice and if I I don't And it would be nice and if I I don't And it would be nice and if I I don't know how they're being differentiated, know how they're being differentiated, know how they're being differentiated, but I think that's important. I see them but I think that's important. I see them but I think that's important. I see them always looped together, but in terms of always looped together, but in terms of always looped together, but in terms of who affects what from an overall cyber who affects what from an overall cyber who affects what from an overall cyber security perspective and the security perspective and the security perspective and the mitigations, any thoughts on that from mitigations, any thoughts on that from mitigations, any thoughts on that from your perspective? Thank you. That's it's your perspective? Thank you. That's it's your perspective? Thank you. That's it's a great question and you know this is a a great question and you know this is a a great question and you know this is a really a in a way kind of paradigm shift really a in a way kind of paradigm shift really a in a way kind of paradigm shift here about how we treating these risks here about how we treating these risks here about how we treating these risks because the data that been used to train because the data that been used to train because the data that been used to train models right in a way that's models right in a way that's models right in a way that's your let's call it that's that's your let's call it that's that's your let's call it that's that's actually your developer actually your developer actually your developer right thinking that creates the right thinking that creates the right thinking that creates the functionality that you want to achieve. functionality that you want to achieve. functionality that you want to achieve. So it's really tied together, right? So it's really tied together, right? So it's really tied together, right? because manipulating the data can because manipulating the data can because manipulating the data can manipulate or result in very serious manipulate or result in very serious manipulate or result in very serious consequences in the operation of the consequences in the operation of the consequences in the operation of the model or or the operation of the model or or the operation of the model or or the operation of the software that rubs the model and software that rubs the model and software that rubs the model and provides the I would say the responses provides the I would say the responses provides the I would say the responses for the request because eventually you for the request because eventually you for the request because eventually you know like it's all these models they are know like it's all these models they are know like it's all these models they are exposed through APIs right so there's exposed through APIs right so there's exposed through APIs right so there's like software that wrapping these models like software that wrapping these models like software that wrapping these models there is also like inenting AI there's there is also like inenting AI there's there is also like inenting AI there's there is a software piece is that there is a software piece is that there is a software piece is that actually building the tools that the actually building the tools that the actually building the tools that the model you can use in order to reach out model you can use in order to reach out model you can use in order to reach out to the outer world. I would say to the to the outer world. I would say to the to the outer world. I would say to the public domain also to the data sources public domain also to the data sources public domain also to the data sources inside the company, right? And of course inside the company, right? And of course inside the company, right? And of course with data sources we have the with data sources we have the with data sources we have the traditional problems, right? I mean traditional problems, right? I mean traditional problems, right? I mean someone can if if data is not sanitized someone can if if data is not sanitized someone can if if data is not sanitized or not treated properly, it can of or not treated properly, it can of or not treated properly, it can of course cause a vulnerability and course cause a vulnerability and course cause a vulnerability and exploitation of vulnerability. But here exploitation of vulnerability. But here exploitation of vulnerability. But here the data actually training the model. So the data actually training the model. So the data actually training the model. So it's embedded inside the model and it it's embedded inside the model and it it's embedded inside the model and it can affect the course of I would say can affect the course of I would say can affect the course of I would say decision or inference that running decision or inference that running decision or inference that running through the model and giving the through the model and giving the through the model and giving the output. I hope it answers the question. Well, I guess we're done. All question. Well, I guess we're done. All question. Well, I guess we're done. All right. Thank you. Thank you everyone.