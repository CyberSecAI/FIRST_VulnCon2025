Kind: captions Language: en Hi everyone, welcome to the first VCON Hi everyone, welcome to the first VCON Hi everyone, welcome to the first VCON 2025 session on securing the future, 2025 session on securing the future, 2025 session on securing the future, navigating AI vulnerabilities and navigating AI vulnerabilities and navigating AI vulnerabilities and evolving security practices. I am Lisa evolving security practices. I am Lisa evolving security practices. I am Lisa Bradley and I have my partner here, Bradley and I have my partner here, Bradley and I have my partner here, Sarah Evans. We're going to do a quick introduction. I could figure out how to introduction. I could figure out how to introduction. I could figure out how to change the page. There we go. Okay. So, There we go. Okay. So, There we go. Okay. So, um, again, Lisa Bradley. I'm a senior um, again, Lisa Bradley. I'm a senior um, again, Lisa Bradley. I'm a senior director for Dell Technologies in the director for Dell Technologies in the director for Dell Technologies in the product and application security space. product and application security space. product and application security space. I call my team Prada which we focus on I call my team Prada which we focus on I call my team Prada which we focus on product remediation and dependency product remediation and dependency product remediation and dependency assurance primarily focusing on product assurance primarily focusing on product assurance primarily focusing on product security and ensuring that we know about security and ensuring that we know about security and ensuring that we know about all of our dependencies and that we are all of our dependencies and that we are all of our dependencies and that we are um knowing about the vulnerabilities in um knowing about the vulnerabilities in um knowing about the vulnerabilities in our dependencies. So per PERT is also our dependencies. So per PERT is also our dependencies. So per PERT is also underneath me. We also drive remediation underneath me. We also drive remediation underneath me. We also drive remediation of other control gaps like weaknesses of other control gaps like weaknesses of other control gaps like weaknesses besides just vulnerabilities. I've been besides just vulnerabilities. I've been besides just vulnerabilities. I've been in security space for over 12 years. Um in security space for over 12 years. Um in security space for over 12 years. Um I went to uh Jennisio for my undergrad I went to uh Jennisio for my undergrad I went to uh Jennisio for my undergrad and NC State for my PhD and I also have and NC State for my PhD and I also have and NC State for my PhD and I also have done uh teaching uh for uh 12 years done uh teaching uh for uh 12 years done uh teaching uh for uh 12 years where I taught on the side while I've where I taught on the side while I've where I taught on the side while I've been working full-time. So I started off been working full-time. So I started off been working full-time. So I started off my career at IBM, I went to Nvidia for a my career at IBM, I went to Nvidia for a my career at IBM, I went to Nvidia for a few years and I've been at Dell for over few years and I've been at Dell for over few years and I've been at Dell for over five five five years. Okay, Sarah, why don't you do years. Okay, Sarah, why don't you do years. Okay, Sarah, why don't you do your intro? your intro? your intro? Yeah. So, um, I work in the office of Yeah. So, um, I work in the office of Yeah. So, um, I work in the office of the CTO. I do security innovation the CTO. I do security innovation the CTO. I do security innovation research. This means that I get to take research. This means that I get to take research. This means that I get to take my IT operations and security operations my IT operations and security operations my IT operations and security operations background and bring it up to the background and bring it up to the background and bring it up to the beginning of design life cycle for Dell beginning of design life cycle for Dell beginning of design life cycle for Dell products and services and really think products and services and really think products and services and really think about how the technology that we're about how the technology that we're about how the technology that we're experimenting with and innovating with experimenting with and innovating with experimenting with and innovating with may affect our customers security and may affect our customers security and may affect our customers security and supply chain. Uh I have um an MBA from supply chain. Uh I have um an MBA from supply chain. Uh I have um an MBA from Missouri State University and have also Missouri State University and have also Missouri State University and have also taught in the computer information taught in the computer information taught in the computer information systems program there. I am a veteran of systems program there. I am a veteran of systems program there. I am a veteran of the Air Force. I did retired after 21 the Air Force. I did retired after 21 the Air Force. I did retired after 21 years. And when I'm not uh trying to years. And when I'm not uh trying to years. And when I'm not uh trying to figure out how to help improve the figure out how to help improve the figure out how to help improve the security industry, I am hanging out with security industry, I am hanging out with security industry, I am hanging out with my family and my two golden retrievers. Great. So let's get started here. When Great. So let's get started here. When Great. So let's get started here. When we think about um AI in our space and we think about um AI in our space and we think about um AI in our space and AI, it's really been growing in the AI, it's really been growing in the AI, it's really been growing in the software product space. So we started software product space. So we started software product space. So we started off where you know AI would give you off where you know AI would give you off where you know AI would give you personalized content or hey personalized content or hey personalized content or hey recommendations, maybe you should like recommendations, maybe you should like recommendations, maybe you should like this or you might like that. We then this or you might like that. We then this or you might like that. We then started to see more AI powered chat bots started to see more AI powered chat bots started to see more AI powered chat bots within our products and virtual within our products and virtual within our products and virtual assistants um to you know to help assistants um to you know to help assistants um to you know to help navigate with our our users that are navigate with our our users that are navigate with our our users that are using our our products. Then all of a using our our products. Then all of a using our our products. Then all of a sudden, you know, as we keep advancing sudden, you know, as we keep advancing sudden, you know, as we keep advancing in here, we've realized that AI tools in here, we've realized that AI tools in here, we've realized that AI tools can actually generate our code snippets, can actually generate our code snippets, can actually generate our code snippets, identify bugs, and really do a lot of identify bugs, and really do a lot of identify bugs, and really do a lot of the coding or support our coding efforts the coding or support our coding efforts the coding or support our coding efforts behind the software within our products. behind the software within our products. behind the software within our products. Um, we've also been focusing on learning Um, we've also been focusing on learning Um, we've also been focusing on learning about more how we could do a more about more how we could do a more about more how we could do a more automation testing with AI to ensure automation testing with AI to ensure automation testing with AI to ensure that our software is uh higher quality that our software is uh higher quality that our software is uh higher quality with fewer defects. As we keep going with fewer defects. As we keep going with fewer defects. As we keep going along the path here, we then are seeing along the path here, we then are seeing along the path here, we then are seeing AI being used in analyzing historical AI being used in analyzing historical AI being used in analyzing historical data to make predictions about future data to make predictions about future data to make predictions about future trends and behaviors and then also trends and behaviors and then also trends and behaviors and then also processing data in real time to make processing data in real time to make processing data in real time to make quick uh decisions based on current quick uh decisions based on current quick uh decisions based on current information. We know that AI will information. We know that AI will information. We know that AI will continue to be integrated more and more continue to be integrated more and more continue to be integrated more and more into the software, enhancing all of our into the software, enhancing all of our into the software, enhancing all of our product capabilities. And I like to joke product capabilities. And I like to joke product capabilities. And I like to joke around, but I actually had AI even around, but I actually had AI even around, but I actually had AI even generate this slide. So AI is um you generate this slide. So AI is um you generate this slide. So AI is um you know an evolving space that we have been know an evolving space that we have been know an evolving space that we have been paying attention to and we're going to paying attention to and we're going to paying attention to and we're going to focus on within this presentation. You want to take this presentation. You want to take this presentation. You want to take this slide or Sarah you want me. Hey Lisa. Um, did you advance to the Hey Lisa. Um, did you advance to the Hey Lisa. Um, did you advance to the next slide? I did. So, I have a little next slide? I did. So, I have a little next slide? I did. So, I have a little delay on my end. Okay, I'm seeing the AI delay on my end. Okay, I'm seeing the AI delay on my end. Okay, I'm seeing the AI threat sources now. Sorry for that. threat sources now. Sorry for that. threat sources now. Sorry for that. Perfect. Awkward pause there. Okay. So, Perfect. Awkward pause there. Okay. So, Perfect. Awkward pause there. Okay. So, as somebody who has a security as somebody who has a security as somebody who has a security operations and an IT background, we talk operations and an IT background, we talk operations and an IT background, we talk a lot about risk and what type of risk a lot about risk and what type of risk a lot about risk and what type of risk we're trying to reduce. And so I became we're trying to reduce. And so I became we're trying to reduce. And so I became very interested in understanding what is very interested in understanding what is very interested in understanding what is happening in these machine learning happening in these machine learning happening in these machine learning models and these large language models models and these large language models models and these large language models that's adding new areas of risk. And so that's adding new areas of risk. And so that's adding new areas of risk. And so um I went uh over the past year and I um I went uh over the past year and I um I went uh over the past year and I earned a certificate through a earned a certificate through a earned a certificate through a university kind of really honing in on university kind of really honing in on university kind of really honing in on um AI and ML. And then I brought back um AI and ML. And then I brought back um AI and ML. And then I brought back what I learned to how we were talking what I learned to how we were talking what I learned to how we were talking about risk and how we were talking at about risk and how we were talking at about risk and how we were talking at about AI in the security community. And about AI in the security community. And about AI in the security community. And so internally at Dell, we were so internally at Dell, we were so internally at Dell, we were developing our, you know, our threat developing our, you know, our threat developing our, you know, our threat modeling team was developing a library modeling team was developing a library modeling team was developing a library of AI threats. And then also we were of AI threats. And then also we were of AI threats. And then also we were seeing some really great industry uh seeing some really great industry uh seeing some really great industry uh resources like OASP coming up with top resources like OASP coming up with top resources like OASP coming up with top 10s for machine learning and large 10s for machine learning and large 10s for machine learning and large language models that I thought were very language models that I thought were very language models that I thought were very compelling. And so this slide actually compelling. And so this slide actually compelling. And so this slide actually puts leverages the or this visual puts leverages the or this visual puts leverages the or this visual leverages the um aggregate uh machine leverages the um aggregate uh machine leverages the um aggregate uh machine learning and LLM uh top 10. And what learning and LLM uh top 10. And what learning and LLM uh top 10. And what you'll see is like that little burglar you'll see is like that little burglar you'll see is like that little burglar that little burglar face those are um that little burglar face those are um that little burglar face those are um risks or those are threats. And so what risks or those are threats. And so what risks or those are threats. And so what they assign to the different parts of an they assign to the different parts of an they assign to the different parts of an architecture that say hey based on how architecture that say hey based on how architecture that say hey based on how the AI the application is leveraging AI the AI the application is leveraging AI the AI the application is leveraging AI in its in its processes here's where you in its in its processes here's where you in its in its processes here's where you have a risk of um leveraging AI have a risk of um leveraging AI have a risk of um leveraging AI components in that application. And so components in that application. And so components in that application. And so as we start to look at these different as we start to look at these different as we start to look at these different threat sources, it starts to give us a threat sources, it starts to give us a threat sources, it starts to give us a really nice way to identify what are really nice way to identify what are really nice way to identify what are those risks and then above and beyond those risks and then above and beyond those risks and then above and beyond that, what um where are these risks um that, what um where are these risks um that, what um where are these risks um part of an an initial system and where part of an an initial system and where part of an an initial system and where are they in a a maybe potentially new or are they in a a maybe potentially new or are they in a a maybe potentially new or expanded risk in a system that we expanded risk in a system that we expanded risk in a system that we haven't classically seen in the haven't classically seen in the haven't classically seen in the past. Lisa, past. Lisa, past. Lisa, right? So when we think about um our AI right? So when we think about um our AI right? So when we think about um our AI related vulnerabilities and we want to related vulnerabilities and we want to related vulnerabilities and we want to start thinking about it, we have to talk start thinking about it, we have to talk start thinking about it, we have to talk think about three different aspects think about three different aspects think about three different aspects here. When we are utilizing AI, um we here. When we are utilizing AI, um we here. When we are utilizing AI, um we have to make sure that we are protecting have to make sure that we are protecting have to make sure that we are protecting the data that we're actually putting the data that we're actually putting the data that we're actually putting into the system. So if you're asking it into the system. So if you're asking it into the system. So if you're asking it questions and things like that or questions and things like that or questions and things like that or feeding it in parts of your code, you feeding it in parts of your code, you feeding it in parts of your code, you want to make sure that your system is want to make sure that your system is want to make sure that your system is protected to make sure that none of your protected to make sure that none of your protected to make sure that none of your proprietary data or IP data is leaking proprietary data or IP data is leaking proprietary data or IP data is leaking out of it. So you need to think about out of it. So you need to think about out of it. So you need to think about extending your security vulnerabilities extending your security vulnerabilities extending your security vulnerabilities related to AI in the space of I am related to AI in the space of I am related to AI in the space of I am putting my information into a system, putting my information into a system, putting my information into a system, how do I protect it? We then think about how do I protect it? We then think about how do I protect it? We then think about in the AI space about the different in the AI space about the different in the AI space about the different components. So we have to think about components. So we have to think about components. So we have to think about our training models, our regular models our training models, our regular models our training models, our regular models of the model response, all of that data of the model response, all of that data of the model response, all of that data and the training data and making sure and the training data and making sure and the training data and making sure that the different components that are that the different components that are that the different components that are involved with the AI space are actually involved with the AI space are actually involved with the AI space are actually protected. So we need to go and extend protected. So we need to go and extend protected. So we need to go and extend our security hygiene principles to those our security hygiene principles to those our security hygiene principles to those AI specific components that are within AI specific components that are within AI specific components that are within the application. And lastly, what we the application. And lastly, what we the application. And lastly, what we have to remember is that this is running have to remember is that this is running have to remember is that this is running on a system. So we need to make sure on a system. So we need to make sure on a system. So we need to make sure that we're applying a regular that we're applying a regular that we're applying a regular application security hygiene on the data application security hygiene on the data application security hygiene on the data and our software. So it what's happening and our software. So it what's happening and our software. So it what's happening in the AI space is a lot of people are in the AI space is a lot of people are in the AI space is a lot of people are moving very quickly because they want to moving very quickly because they want to moving very quickly because they want to use AI. They want to utilize it. They use AI. They want to utilize it. They use AI. They want to utilize it. They want to get the benefits from it. But we want to get the benefits from it. But we want to get the benefits from it. But we have to remember that we have to protect have to remember that we have to protect have to remember that we have to protect it in every aspect in every sense of the it in every aspect in every sense of the it in every aspect in every sense of the way. whether it's the data we're putting way. whether it's the data we're putting way. whether it's the data we're putting in and to train it or the constant data in and to train it or the constant data in and to train it or the constant data we're feeding it when we're actually we're feeding it when we're actually we're feeding it when we're actually utilizing it or the system that it's on. utilizing it or the system that it's on. utilizing it or the system that it's on. So when we're thinking about our AI So when we're thinking about our AI So when we're thinking about our AI related vulnerabilities, they can related vulnerabilities, they can related vulnerabilities, they can actually be found in all stages of the actually be found in all stages of the actually be found in all stages of the AI life cycle and the supply chain. So AI life cycle and the supply chain. So AI life cycle and the supply chain. So including the data, the models and the including the data, the models and the including the data, the models and the actual deployment. So we're thinking actual deployment. So we're thinking actual deployment. So we're thinking about our AI related vulnerabilities about our AI related vulnerabilities about our AI related vulnerabilities that are are weaknesses and you know that are are weaknesses and you know that are are weaknesses and you know that are used um you know not only that are used um you know not only that are used um you know not only within the the applications of the AI within the the applications of the AI within the the applications of the AI but the actual output that you would get but the actual output that you would get but the actual output that you would get from it. So it may be that there is a from it. So it may be that there is a from it. So it may be that there is a vulnerability that existed in the vulnerability that existed in the vulnerability that existed in the training data or the training model and training data or the training model and training data or the training model and then that is then feeding back bad then that is then feeding back bad then that is then feeding back bad information to maybe your end users when information to maybe your end users when information to maybe your end users when they're actually utilizing the system they're actually utilizing the system they're actually utilizing the system and asking it for questions or feedback. and asking it for questions or feedback. and asking it for questions or feedback. So there could be vulnerabilities that So there could be vulnerabilities that So there could be vulnerabilities that the AI system is actually generating for the AI system is actually generating for the AI system is actually generating for you within code that you're getting from you within code that you're getting from you within code that you're getting from it that you that and it's a new way of it that you that and it's a new way of it that you that and it's a new way of thinking like typically if I'm in charge thinking like typically if I'm in charge thinking like typically if I'm in charge of the system and you're my end user of the system and you're my end user of the system and you're my end user using it, you're you're just thinking, using it, you're you're just thinking, using it, you're you're just thinking, hey, keep that system updated and hey, keep that system updated and hey, keep that system updated and protected and I'm good. But I might have protected and I'm good. But I might have protected and I'm good. But I might have to say to you, hey, there was a to say to you, hey, there was a to say to you, hey, there was a vulnerability in like the data that we vulnerability in like the data that we vulnerability in like the data that we actually fed into the system and that actually fed into the system and that actually fed into the system and that might have gave you bad output and might have gave you bad output and might have gave you bad output and therefore you now need to do some action therefore you now need to do some action therefore you now need to do some action because you potentially would have because you potentially would have because you potentially would have gotten bad output. And this is a gotten bad output. And this is a gotten bad output. And this is a different way of thinking when we think different way of thinking when we think different way of thinking when we think about vulnerabilities for a system that about vulnerabilities for a system that about vulnerabilities for a system that maybe you know a big corp type of you maybe you know a big corp type of you maybe you know a big corp type of you know is maintaining but you were just know is maintaining but you were just know is maintaining but you were just the end user of the using it. you might the end user of the using it. you might the end user of the using it. you might now might need to know about a now might need to know about a now might need to know about a vulnerability because it might have vulnerability because it might have vulnerability because it might have caused bad content that you now caused bad content that you now caused bad content that you now collected. So when we're thinking about collected. So when we're thinking about collected. So when we're thinking about the threats and the future of what AI is the threats and the future of what AI is the threats and the future of what AI is going to do in our in our in our core going to do in our in our in our core going to do in our in our in our core threat landscape, we believe that there threat landscape, we believe that there threat landscape, we believe that there are three main areas that we are going are three main areas that we are going are three main areas that we are going to see um more threat threat actors to see um more threat threat actors to see um more threat threat actors playing with. So first is poor system playing with. So first is poor system playing with. So first is poor system architecture and operation operational architecture and operation operational architecture and operation operational hygiene. So this will provide rich hygiene. So this will provide rich hygiene. So this will provide rich attack services to threat actors. As I attack services to threat actors. As I attack services to threat actors. As I was saying, people are moving very was saying, people are moving very was saying, people are moving very quickly in the space. So if they're not quickly in the space. So if they're not quickly in the space. So if they're not protecting and not doing all the right protecting and not doing all the right protecting and not doing all the right the right protection along the way or the right protection along the way or the right protection along the way or designing it in the right way, then it's designing it in the right way, then it's designing it in the right way, then it's easier to be um to to have uh bad actors easier to be um to to have uh bad actors easier to be um to to have uh bad actors go and and infiltrate those systems. go and and infiltrate those systems. go and and infiltrate those systems. Then thinking about the supply chain of Then thinking about the supply chain of Then thinking about the supply chain of security. So poorly integrated supply security. So poorly integrated supply security. So poorly integrated supply chain security will cause you know like chain security will cause you know like chain security will cause you know like an upstream vulnerability in the AI an upstream vulnerability in the AI an upstream vulnerability in the AI technology. So we've been we're technology. So we've been we're technology. So we've been we're innovating and we're innovating in the innovating and we're innovating in the innovating and we're innovating in the space but we need to make sure that space but we need to make sure that space but we need to make sure that we're protecting along in the supply we're protecting along in the supply we're protecting along in the supply chain and if we don't we which is like I chain and if we don't we which is like I chain and if we don't we which is like I said we're moving so quickly and we're said we're moving so quickly and we're said we're moving so quickly and we're grabbing data here models from here grabbing data here models from here grabbing data here models from here models from there when we're putting all models from there when we're putting all models from there when we're putting all that stuff together into a system if that stuff together into a system if that stuff together into a system if we're not uh having strong security we're not uh having strong security we're not uh having strong security practices along our supply chain and practices along our supply chain and practices along our supply chain and making sure that those components or making sure that those components or making sure that those components or those different suppliers that we're those different suppliers that we're those different suppliers that we're using to get that information have good using to get that information have good using to get that information have good hygiene and practices. is then we're hygiene and practices. is then we're hygiene and practices. is then we're going to allow another another um area going to allow another another um area going to allow another another um area that that actors can that actors can act that that actors can that actors can act that that actors can that actors can act on. And the last is on that actual data on. And the last is on that actual data on. And the last is on that actual data management and management and management and classification. So the data management classification. So the data management classification. So the data management of of the data going in and what are we of of the data going in and what are we of of the data going in and what are we doing when we're getting more and more doing when we're getting more and more doing when we're getting more and more data fed into the system. we need to data fed into the system. we need to data fed into the system. we need to make sure that we are doing the proper make sure that we are doing the proper make sure that we are doing the proper management classification so that no um management classification so that no um management classification so that no um there's no IP leakage of any information there's no IP leakage of any information there's no IP leakage of any information or the fact that there's no infiltration or the fact that there's no infiltration or the fact that there's no infiltration into that data set that we're going to into that data set that we're going to into that data set that we're going to be feeding into the system. be feeding into the system. be feeding into the system. So when we think about our So when we think about our So when we think about our identification and classification of AI identification and classification of AI identification and classification of AI vulnerabilities, there are three vulnerabilities, there are three vulnerabilities, there are three different areas. We need to think about different areas. We need to think about different areas. We need to think about the actual the actual the actual stage. Sorry, I think I'm going to stage. Sorry, I think I'm going to stage. Sorry, I think I'm going to sneeze. The actual um stage of where sneeze. The actual um stage of where sneeze. The actual um stage of where that uh where that that vulnerability that uh where that that vulnerability that uh where that that vulnerability might have been identified. Is it might have been identified. Is it might have been identified. Is it through the sourcing? Is it through through the sourcing? Is it through through the sourcing? Is it through training? Is it through the hosting? Is training? Is it through the hosting? Is training? Is it through the hosting? Is it through the production or it through the production or it through the production or maintenance? And then what are the goals maintenance? And then what are the goals maintenance? And then what are the goals right of a bad actor? Is it to sabotage? right of a bad actor? Is it to sabotage? right of a bad actor? Is it to sabotage? Is it fraud? Is it trying to get, you Is it fraud? Is it trying to get, you Is it fraud? Is it trying to get, you know, the information, the IP know, the information, the IP know, the information, the IP information? And then think about the information? And then think about the information? And then think about the different um attack types. Um these are different um attack types. Um these are different um attack types. Um these are just a few poisoning, poisoning, just a few poisoning, poisoning, just a few poisoning, poisoning, interference, backdooring, interference, backdooring, interference, backdooring, reprogramming, evasion. And you're going reprogramming, evasion. And you're going reprogramming, evasion. And you're going to have to think about these to have to think about these to have to think about these collectively to figure out, you know, collectively to figure out, you know, collectively to figure out, you know, how are you going to do your how are you going to do your how are you going to do your classification of your AI classification of your AI classification of your AI vulnerabilities. So this is a new space vulnerabilities. So this is a new space vulnerabilities. So this is a new space for all of us in in this in this how do for all of us in in this in this how do for all of us in in this in this how do I define vulnerabilities in the AI I define vulnerabilities in the AI I define vulnerabilities in the AI space. When do I define and assign like space. When do I define and assign like space. When do I define and assign like a CVE versus when do I not? So thinking a CVE versus when do I not? So thinking a CVE versus when do I not? So thinking about that stage, the goals and the about that stage, the goals and the about that stage, the goals and the types are really going to be important types are really going to be important types are really going to be important when we're thinking about how we're when we're thinking about how we're when we're thinking about how we're going to go and classify our going to go and classify our going to go and classify our vulnerabilities in this vulnerabilities in this vulnerabilities in this space. So let's talk and uh take an space. So let's talk and uh take an space. So let's talk and uh take an example here of of data poisoning. So example here of of data poisoning. So example here of of data poisoning. So this is a type of cyber attack where this is a type of cyber attack where this is a type of cyber attack where somebody goes and intentionally somebody goes and intentionally somebody goes and intentionally manipulates the data used to develop or manipulates the data used to develop or manipulates the data used to develop or use an AI or machine learning model. So use an AI or machine learning model. So use an AI or machine learning model. So there are just a few samples of this there are just a few samples of this there are just a few samples of this that we have on the slide here. Things that we have on the slide here. Things that we have on the slide here. Things like label flipping. There's correct, like label flipping. There's correct, like label flipping. There's correct, you know, correct labels in the training you know, correct labels in the training you know, correct labels in the training data are swapped with incorrect ones. data are swapped with incorrect ones. data are swapped with incorrect ones. Data injection where there are data Data injection where there are data Data injection where there are data points that are added to the training points that are added to the training points that are added to the training set that are malicious. set that are malicious. set that are malicious. Then we think of a backdoor attack. So Then we think of a backdoor attack. So Then we think of a backdoor attack. So this is where the model is trained to this is where the model is trained to this is where the model is trained to behave normally except when a specific behave normally except when a specific behave normally except when a specific trigger sort of is present and then it trigger sort of is present and then it trigger sort of is present and then it acts differently. And then also with the acts differently. And then also with the acts differently. And then also with the labeling there could be modifying the labeling there could be modifying the labeling there could be modifying the training data without changing the training data without changing the training data without changing the labels. So here the idea is is that they labels. So here the idea is is that they labels. So here the idea is is that they are poisoning the data that's fed in to are poisoning the data that's fed in to are poisoning the data that's fed in to um the system. So um then then when you um the system. So um then then when you um the system. So um then then when you as an end user are using that system, as an end user are using that system, as an end user are using that system, you potentially are going to get bad you potentially are going to get bad you potentially are going to get bad data or bad malicious things out of it. So when we think about protecting it. So when we think about protecting it. So when we think about protecting our data and our data models along the our data and our data models along the our data and our data models along the way and where we're getting things or way and where we're getting things or way and where we're getting things or our different components in the AI our different components in the AI our different components in the AI space, we can think about supply chain space, we can think about supply chain space, we can think about supply chain that way. So typically we think about that way. So typically we think about that way. So typically we think about supply chain and traditionally it's supply chain and traditionally it's supply chain and traditionally it's focusing on like building we're in Dell focusing on like building we're in Dell focusing on like building we're in Dell so I'm going to say building a laptop so I'm going to say building a laptop so I'm going to say building a laptop right all the different parts along the right all the different parts along the right all the different parts along the way and the manufacturers and the way and the manufacturers and the way and the manufacturers and the different parts here we get the chip different parts here we get the chip different parts here we get the chip here we get this the memory and all that here we get this the memory and all that here we get this the memory and all that we're putting something together and the we're putting something together and the we're putting something together and the idea of AI related supply chain this is idea of AI related supply chain this is idea of AI related supply chain this is a focusing on the fact that we're using a focusing on the fact that we're using a focusing on the fact that we're using thirdparty data sets pre-trained models thirdparty data sets pre-trained models thirdparty data sets pre-trained models and plugins all of these like any supply and plugins all of these like any supply and plugins all of these like any supply chain can add weaknesses you're only as chain can add weaknesses you're only as chain can add weaknesses you're only as secure as your weakest point within your secure as your weakest point within your secure as your weakest point within your system. So AI supply chain attacks can system. So AI supply chain attacks can system. So AI supply chain attacks can occur when attack modifies or replace occur when attack modifies or replace occur when attack modifies or replace some machine learning library, a model some machine learning library, a model some machine learning library, a model within the system, especially in the within the system, especially in the within the system, especially in the case when if it's a poisoning of some case when if it's a poisoning of some case when if it's a poisoning of some kind of a sample within our training kind of a sample within our training kind of a sample within our training data. So we have to think about how do data. So we have to think about how do data. So we have to think about how do we best protect and make sure that when we best protect and make sure that when we best protect and make sure that when we're getting something like training we're getting something like training we're getting something like training data that it didn't have any type of bad data that it didn't have any type of bad data that it didn't have any type of bad data in it. it wasn't poisoned along the data in it. it wasn't poisoned along the data in it. it wasn't poisoned along the way to get it to you know the the system way to get it to you know the the system way to get it to you know the the system that is now going to be housing it. So that is now going to be housing it. So that is now going to be housing it. So it could also include the data it could also include the data it could also include the data associated within the machine machine associated within the machine machine associated within the machine machine learning uh models when we think about learning uh models when we think about learning uh models when we think about the supply chain tech. So just a the supply chain tech. So just a the supply chain tech. So just a different way of thinking that we need different way of thinking that we need different way of thinking that we need to start thinking about when we're to start thinking about when we're to start thinking about when we're putting all these components together, putting all these components together, putting all these components together, the data together, the training models the data together, the training models the data together, the training models together, and making sure that like all together, and making sure that like all together, and making sure that like all of the security and and the supply chain of the security and and the supply chain of the security and and the supply chain in the security of all the suppliers in the security of all the suppliers in the security of all the suppliers that we're using along the way are that we're using along the way are that we're using along the way are strong so that when we build our system strong so that when we build our system strong so that when we build our system all together, we have a strong system all together, we have a strong system all together, we have a strong system with with our our data not being not with with our our data not being not with with our our data not being not being poisoned. in this being poisoned. in this being poisoned. in this example. Okay, Sarah, so I'm gonna pass example. Okay, Sarah, so I'm gonna pass example. Okay, Sarah, so I'm gonna pass over to you. over to you. over to you. Yeah. So, Lisa has done a really great Yeah. So, Lisa has done a really great Yeah. So, Lisa has done a really great job of describing vulnerabilities, job of describing vulnerabilities, job of describing vulnerabilities, threats, um, and how we've thought about threats, um, and how we've thought about threats, um, and how we've thought about these things in the supply chain. And so these things in the supply chain. And so these things in the supply chain. And so now what I'm asking is for you to um now what I'm asking is for you to um now what I'm asking is for you to um kind of pivot forward on what you may kind of pivot forward on what you may kind of pivot forward on what you may know about uh vulnerability remediation know about uh vulnerability remediation know about uh vulnerability remediation and start to evaluate if when these and start to evaluate if when these and start to evaluate if when these future AI component vulnerabilities future AI component vulnerabilities future AI component vulnerabilities evolve, how we can extend our current evolve, how we can extend our current evolve, how we can extend our current business practices at the enterprise, business practices at the enterprise, business practices at the enterprise, our controls, our compliance, our our controls, our compliance, our our controls, our compliance, our software development life cycle um to software development life cycle um to software development life cycle um to extend to be inclusive extend to be inclusive extend to be inclusive of these AI components that have risks of these AI components that have risks of these AI components that have risks and threats to them that will become a and threats to them that will become a and threats to them that will become a part of our supply chain. And so, for part of our supply chain. And so, for part of our supply chain. And so, for example, you know, with software example, you know, with software example, you know, with software vulnerabilities, we've been building vulnerabilities, we've been building vulnerabilities, we've been building inventories of software. We've been inventories of software. We've been inventories of software. We've been leveraging software bills of materials. leveraging software bills of materials. leveraging software bills of materials. We've been working to coordinate We've been working to coordinate We've been working to coordinate communication plans in our development communication plans in our development communication plans in our development life cycle with our engineering team so life cycle with our engineering team so life cycle with our engineering team so that when a vulnerability is reported, that when a vulnerability is reported, that when a vulnerability is reported, we can work with that engineering team, we can work with that engineering team, we can work with that engineering team, you know, based on our inventories to you know, based on our inventories to you know, based on our inventories to understand if we're affected. we can understand if we're affected. we can understand if we're affected. we can work on a patch. We can communicate with work on a patch. We can communicate with work on a patch. We can communicate with our customers that I believe that that our customers that I believe that that our customers that I believe that that process is going to still need to be in process is going to still need to be in process is going to still need to be in place as we start to introduce AI place as we start to introduce AI place as we start to introduce AI components. So, thinking about some of components. So, thinking about some of components. So, thinking about some of these new AI components, your data set, these new AI components, your data set, these new AI components, your data set, your model itself, a model card that was your model itself, a model card that was your model itself, a model card that was um given to you with that model that um given to you with that model that um given to you with that model that said what data set it was trained on. said what data set it was trained on. said what data set it was trained on. Um, thinking about how we're leveraging Um, thinking about how we're leveraging Um, thinking about how we're leveraging new types of databases like vector new types of databases like vector new types of databases like vector databases. um rag architecture for databases. um rag architecture for databases. um rag architecture for retrieval, augmented generation, um retrieval, augmented generation, um retrieval, augmented generation, um agents and agent architectures and agents and agent architectures and agents and agent architectures and frameworks, knowledge graphs. Um we want frameworks, knowledge graphs. Um we want frameworks, knowledge graphs. Um we want to extend the way we capture the to extend the way we capture the to extend the way we capture the inventory of these things. Um we will inventory of these things. Um we will inventory of these things. Um we will need to start thinking about how do we need to start thinking about how do we need to start thinking about how do we articulate these components in a bill of articulate these components in a bill of articulate these components in a bill of materials, perhaps an AI software bill materials, perhaps an AI software bill materials, perhaps an AI software bill of materials. Um we will want to of materials. Um we will want to of materials. Um we will want to understand who in our company we need to understand who in our company we need to understand who in our company we need to start coordinating with um when these start coordinating with um when these start coordinating with um when these weaknesses and vulnerabilities exist so weaknesses and vulnerabilities exist so weaknesses and vulnerabilities exist so we can understand if we're affected um we can understand if we're affected um we can understand if we're affected um what what machine readable data do we what what machine readable data do we what what machine readable data do we need to do that analysis um and also to need to do that analysis um and also to need to do that analysis um and also to show due diligence and compliance in our show due diligence and compliance in our show due diligence and compliance in our life cycle processes. Uh, so I think life cycle processes. Uh, so I think life cycle processes. Uh, so I think there's a lot of opportunity for us to there's a lot of opportunity for us to there's a lot of opportunity for us to start proactively thinking about how start proactively thinking about how start proactively thinking about how we're going to need to extend our we're going to need to extend our we're going to need to extend our software vulnerability remediation to be software vulnerability remediation to be software vulnerability remediation to be inclusive of AI components. Google has inclusive of AI components. Google has inclusive of AI components. Google has done a lot of really great work in this done a lot of really great work in this done a lot of really great work in this space. On the right side of the screen, space. On the right side of the screen, space. On the right side of the screen, you can see a screenshot um from their you can see a screenshot um from their you can see a screenshot um from their controls for AI supply chain security controls for AI supply chain security controls for AI supply chain security and their four main recommendations are and their four main recommendations are and their four main recommendations are capture metadata, increase integrity, capture metadata, increase integrity, capture metadata, increase integrity, organize your metadata and share with organize your metadata and share with organize your metadata and share with others. And I think those are somewhat others. And I think those are somewhat others. And I think those are somewhat deceptively simple but right on point deceptively simple but right on point deceptively simple but right on point with where we need to be thinking about with where we need to be thinking about with where we need to be thinking about um underneath the the hood as we're um underneath the the hood as we're um underneath the the hood as we're looking at our internal processes where looking at our internal processes where looking at our internal processes where we need to be evolving. All right, next evolving. All right, next evolving. All right, next slide. Okay, so now I'm going to give slide. Okay, so now I'm going to give slide. Okay, so now I'm going to give you a use case. Um, so this is a use you a use case. Um, so this is a use you a use case. Um, so this is a use case based off the cyber resiliency act, case based off the cyber resiliency act, case based off the cyber resiliency act, which is a consumer compliance out of which is a consumer compliance out of which is a consumer compliance out of the EU for devices that have digital the EU for devices that have digital the EU for devices that have digital elements in them, such as, you know, elements in them, such as, you know, elements in them, such as, you know, product made by by a technology or product made by by a technology or product made by by a technology or laptop company, infrastructure, and laptop company, infrastructure, and laptop company, infrastructure, and software. Um, in this uh cyber software. Um, in this uh cyber software. Um, in this uh cyber resiliency act, um, we'll need to be resiliency act, um, we'll need to be resiliency act, um, we'll need to be able to report if you know, we don't able to report if you know, we don't able to report if you know, we don't want to ship any products with known want to ship any products with known want to ship any products with known exploitable vulnerabilities. Um, if our exploitable vulnerabilities. Um, if our exploitable vulnerabilities. Um, if our product does have a a known exploitable product does have a a known exploitable product does have a a known exploitable vulnerability after it's um being used vulnerability after it's um being used vulnerability after it's um being used by our customers, we'll need to be able by our customers, we'll need to be able by our customers, we'll need to be able to uh report on that very quickly and to uh report on that very quickly and to uh report on that very quickly and and then o over time we'll need to be and then o over time we'll need to be and then o over time we'll need to be able to maintain patches for those um able to maintain patches for those um able to maintain patches for those um systems. And so in this in this case, systems. And so in this in this case, systems. And so in this in this case, you know, this this regulation applies you know, this this regulation applies you know, this this regulation applies to the software. Um, but in a couple to the software. Um, but in a couple to the software. Um, but in a couple years as we're starting to respond to AI years as we're starting to respond to AI years as we're starting to respond to AI vulnerabilities, I believe that it will vulnerabilities, I believe that it will vulnerabilities, I believe that it will also, you know, extend to the way we also, you know, extend to the way we also, you know, extend to the way we need to respond to AI vulnerabilities in need to respond to AI vulnerabilities in need to respond to AI vulnerabilities in those products as well. So we'll need to those products as well. So we'll need to those products as well. So we'll need to be able to very quickly understand you be able to very quickly understand you be able to very quickly understand you know as an example in our use case if know as an example in our use case if know as an example in our use case if the data set that we used to train a the data set that we used to train a the data set that we used to train a model was poisoned and our attorneys model was poisoned and our attorneys model was poisoned and our attorneys were saying hey we need to identify were saying hey we need to identify were saying hey we need to identify where that model is um and uh you know where that model is um and uh you know where that model is um and uh you know notify our customers swap it out etc. Do notify our customers swap it out etc. Do notify our customers swap it out etc. Do we have the machine readable data points we have the machine readable data points we have the machine readable data points and the due diligence and uh attestation and the due diligence and uh attestation and the due diligence and uh attestation throughout the process to understand you throughout the process to understand you throughout the process to understand you know where we brought in models trained know where we brought in models trained know where we brought in models trained on that data set um where we may have on that data set um where we may have on that data set um where we may have fine-tuned models with the data set and fine-tuned models with the data set and fine-tuned models with the data set and how those eventually were rolled up into how those eventually were rolled up into how those eventually were rolled up into an container and application and shared an container and application and shared an container and application and shared with our customers. Um so that is going with our customers. Um so that is going with our customers. Um so that is going to be kind of an area that we all need to be kind of an area that we all need to be kind of an area that we all need to as an industry lean in to understand to as an industry lean in to understand to as an industry lean in to understand how to create those uh machine readable how to create those uh machine readable how to create those uh machine readable data points and I think also this is data points and I think also this is data points and I think also this is going to bring us into being able to going to bring us into being able to going to bring us into being able to have what uh converged enterprise um have what uh converged enterprise um have what uh converged enterprise um security operations. So what's security operations. So what's security operations. So what's classically your dev ops or your dev sec classically your dev ops or your dev sec classically your dev ops or your dev sec ops may now need to be inclusive of ops may now need to be inclusive of ops may now need to be inclusive of stakeholders that are doing data ops stakeholders that are doing data ops stakeholders that are doing data ops that are doing ML and LLM ops. And so that are doing ML and LLM ops. And so that are doing ML and LLM ops. And so this conversion over time of our secure this conversion over time of our secure this conversion over time of our secure operations that are going to be required operations that are going to be required operations that are going to be required to build deploy and respond to incidents to build deploy and respond to incidents to build deploy and respond to incidents with AI components um is a concept I'm with AI components um is a concept I'm with AI components um is a concept I'm calling secure X ops. Um, but it's it's calling secure X ops. Um, but it's it's calling secure X ops. Um, but it's it's something that I think that as we're something that I think that as we're something that I think that as we're thinking about evolving compliance for thinking about evolving compliance for thinking about evolving compliance for products and vulnerability remediation products and vulnerability remediation products and vulnerability remediation response, we need to start kind of being response, we need to start kind of being response, we need to start kind of being proactive in thinking forward around proactive in thinking forward around proactive in thinking forward around what maybe what are some gaps and what maybe what are some gaps and what maybe what are some gaps and opportunities to close those gaps before opportunities to close those gaps before opportunities to close those gaps before these use cases um begin to happen in these use cases um begin to happen in these use cases um begin to happen in our products that we can work as an our products that we can work as an our products that we can work as an industry together to industry together to industry together to close. Right. Next close. Right. Next close. Right. Next slide. All right. And so this I believe slide. All right. And so this I believe slide. All right. And so this I believe leads us to this idea of um the parable leads us to this idea of um the parable leads us to this idea of um the parable of the blind men and the elephant. And of the blind men and the elephant. And of the blind men and the elephant. And so in this case you have um an elephant so in this case you have um an elephant so in this case you have um an elephant that was being the different body parts that was being the different body parts that was being the different body parts of the elephant were being felt by blind of the elephant were being felt by blind of the elephant were being felt by blind men and they would describe the same men and they would describe the same men and they would describe the same animal but in different ways based on animal but in different ways based on animal but in different ways based on their perspective of how they were their perspective of how they were their perspective of how they were seeing and approaching the problem. So seeing and approaching the problem. So seeing and approaching the problem. So you know the person holding the trunk you know the person holding the trunk you know the person holding the trunk said, "Oh, it feels like a snake." the said, "Oh, it feels like a snake." the said, "Oh, it feels like a snake." the person holding the trunk said, "Oh, this person holding the trunk said, "Oh, this person holding the trunk said, "Oh, this feels like a sword." Um, and so on as feels like a sword." Um, and so on as feels like a sword." Um, and so on as they but really they're describing they but really they're describing they but really they're describing different parts of the same problem. And different parts of the same problem. And different parts of the same problem. And just like we talked about how the uh how just like we talked about how the uh how just like we talked about how the uh how AI is going to cause um problems that we AI is going to cause um problems that we AI is going to cause um problems that we have currently in the industry to have currently in the industry to have currently in the industry to accelerate u more rapidly. I also think accelerate u more rapidly. I also think accelerate u more rapidly. I also think that thinking about AI applications and that thinking about AI applications and that thinking about AI applications and how do we respond to those incidents is how do we respond to those incidents is how do we respond to those incidents is going to cause us to have to bring in going to cause us to have to bring in going to cause us to have to bring in different stakeholders or different different stakeholders or different different stakeholders or different people touching different parts of the people touching different parts of the people touching different parts of the elements um elephant in ways that we elements um elephant in ways that we elements um elephant in ways that we have may not have yet had to tightly have may not have yet had to tightly have may not have yet had to tightly interact with each other before. So this interact with each other before. So this interact with each other before. So this is similar to that converged secure ops is similar to that converged secure ops is similar to that converged secure ops just like our operational procedures just like our operational procedures just like our operational procedures will be um converging our the way we will be um converging our the way we will be um converging our the way we might attest to things in a machine might attest to things in a machine might attest to things in a machine readable way will potentially start to readable way will potentially start to readable way will potentially start to converge as well. So let's move to the converge as well. So let's move to the converge as well. So let's move to the next slide to see an example of that. next slide to see an example of that. next slide to see an example of that. All right. So, you see, you know, All right. So, you see, you know, All right. So, you see, you know, potentially you have ways that people potentially you have ways that people potentially you have ways that people have uh attested to secure hardware um have uh attested to secure hardware um have uh attested to secure hardware um and what is in a set of hardware that's and what is in a set of hardware that's and what is in a set of hardware that's shipping. Uh ways that you can attest shipping. Uh ways that you can attest shipping. Uh ways that you can attest that this was a data set and a data set that this was a data set and a data set that this was a data set and a data set that was used to train a model. We have that was used to train a model. We have that was used to train a model. We have ways that we've been working really hard ways that we've been working really hard ways that we've been working really hard to improve how we attest to uh software to improve how we attest to uh software to improve how we attest to uh software secure software development practices. secure software development practices. secure software development practices. We attest to a runtime environment. Um We attest to a runtime environment. Um We attest to a runtime environment. Um and and then soon we may need to um and and then soon we may need to um and and then soon we may need to um attest to models, model cards and have attest to models, model cards and have attest to models, model cards and have machine readable ways to um attest that machine readable ways to um attest that machine readable ways to um attest that certain data was processed by a certain certain data was processed by a certain certain data was processed by a certain model. Uh and then kind of going on model. Uh and then kind of going on model. Uh and then kind of going on underneath the bottom across us all, we underneath the bottom across us all, we underneath the bottom across us all, we still have to disclose to governments still have to disclose to governments still have to disclose to governments and compliance, you know, an and compliance, you know, an and compliance, you know, an attestation. This could be a DEO attestation. This could be a DEO attestation. This could be a DEO attestation. It could be something that attestation. It could be something that attestation. It could be something that we do to show due diligence for we do to show due diligence for we do to show due diligence for something like the cyber resiliency act something like the cyber resiliency act something like the cyber resiliency act and even future AI regulations that are and even future AI regulations that are and even future AI regulations that are just now kind of evolving through uh just now kind of evolving through uh just now kind of evolving through uh legal frameworks and processes. So I legal frameworks and processes. So I legal frameworks and processes. So I think this is what I call the AI supply think this is what I call the AI supply think this is what I call the AI supply chain perspectives. And so what I would chain perspectives. And so what I would chain perspectives. And so what I would encourage everyone to do is start encourage everyone to do is start encourage everyone to do is start finding the people in your enterprise, finding the people in your enterprise, finding the people in your enterprise, the people in your industry that may the people in your industry that may the people in your industry that may know a different part of the AI supply know a different part of the AI supply know a different part of the AI supply chain elephant than you do because I chain elephant than you do because I chain elephant than you do because I think it's going to really require um a think it's going to really require um a think it's going to really require um a communication of how do we take things communication of how do we take things communication of how do we take things that have worked effectively in each of that have worked effectively in each of that have worked effectively in each of these different areas and work on a way these different areas and work on a way these different areas and work on a way to where they can be brought together um to where they can be brought together um to where they can be brought together um in a universal attestation uh framework. in a universal attestation uh framework. in a universal attestation uh framework. Next slide. All right. So, this convergence slide. All right. So, this convergence slide. All right. So, this convergence is um really kind of I took each one of is um really kind of I took each one of is um really kind of I took each one of those body parts and kind of have put in those body parts and kind of have put in those body parts and kind of have put in this areas of con convergence. And so as this areas of con convergence. And so as this areas of con convergence. And so as you're looking at them and I this is where I want us to start I this is where I want us to start I this is where I want us to start thinking about how do we need to evolve thinking about how do we need to evolve thinking about how do we need to evolve our business processes in a machine our business processes in a machine our business processes in a machine readable way to where we can attest to readable way to where we can attest to readable way to where we can attest to understanding where different AI understanding where different AI understanding where different AI components in are in our development components in are in our development components in are in our development life cycles that we can quickly respond life cycles that we can quickly respond life cycles that we can quickly respond to vulnerabilities and remediate those to vulnerabilities and remediate those to vulnerabilities and remediate those vulnerabilities. So think about how do vulnerabilities. So think about how do vulnerabilities. So think about how do we extend software and hardware add we extend software and hardware add we extend software and hardware add astations that are already in place to astations that are already in place to astations that are already in place to other AI components and then how are we other AI components and then how are we other AI components and then how are we going to articulate those components and going to articulate those components and going to articulate those components and bills of materials in our inventories bills of materials in our inventories bills of materials in our inventories and with cryptographically assigned and with cryptographically assigned and with cryptographically assigned addistations and how can we begin to in addistations and how can we begin to in addistations and how can we begin to in a machine readable way begin to converge a machine readable way begin to converge a machine readable way begin to converge some of these addestations some of these addestations some of these addestations together. Right, next slide. All right. So, this is a a piece slide. All right. So, this is a a piece slide. All right. So, this is a a piece of what I propose that the industry will of what I propose that the industry will of what I propose that the industry will need as we start to think about a need as we start to think about a need as we start to think about a universal addestation framework in order universal addestation framework in order universal addestation framework in order to be to be able to really identify and to be to be able to really identify and to be to be able to really identify and respond to AI um vulnerabilities in our respond to AI um vulnerabilities in our respond to AI um vulnerabilities in our products. I think that it's going to products. I think that it's going to products. I think that it's going to need to be automated, integrated, and need to be automated, integrated, and need to be automated, integrated, and easy to adopt. We're going to need it to easy to adopt. We're going to need it to easy to adopt. We're going to need it to do three things. it we're we're going to do three things. it we're we're going to do three things. it we're we're going to need to establish integrity, report on need to establish integrity, report on need to establish integrity, report on that integrity, and verify that that integrity, and verify that that integrity, and verify that integrity. And so I don't think we're integrity. And so I don't think we're integrity. And so I don't think we're starting from scratch here. We're not starting from scratch here. We're not starting from scratch here. We're not starting from the very beginning because starting from the very beginning because starting from the very beginning because we do have mechanisms to establish we do have mechanisms to establish we do have mechanisms to establish report and verify integrity already. report and verify integrity already. report and verify integrity already. Some of them are manual. Some of them Some of them are manual. Some of them Some of them are manual. Some of them are in various stages of machine are in various stages of machine are in various stages of machine readability. But when you look across readability. But when you look across readability. But when you look across the convergence, I think that as we the convergence, I think that as we the convergence, I think that as we identify the those those tools and identify the those those tools and identify the those those tools and processes and mechanisms that have processes and mechanisms that have processes and mechanisms that have worked in various areas, the opportunity worked in various areas, the opportunity worked in various areas, the opportunity ahead of the industry today is to ahead of the industry today is to ahead of the industry today is to identify how we want to bring those identify how we want to bring those identify how we want to bring those together into a universal addestation together into a universal addestation together into a universal addestation framework that I believe is going to be framework that I believe is going to be framework that I believe is going to be required for AI applications and required for AI applications and required for AI applications and components. All right, next slide. All right. So, nobody I think right now All right. So, nobody I think right now All right. So, nobody I think right now has a an answer, but I know that based has a an answer, but I know that based has a an answer, but I know that based off of how things have evolved in off of how things have evolved in off of how things have evolved in software development, I see that those software development, I see that those software development, I see that those AI applications and components are going AI applications and components are going AI applications and components are going to really require us to think a little to really require us to think a little to really require us to think a little bit more deeply and proactively around bit more deeply and proactively around bit more deeply and proactively around these different areas. And so what I've these different areas. And so what I've these different areas. And so what I've done is I've put together this slide done is I've put together this slide done is I've put together this slide that talks about those different places that talks about those different places that talks about those different places where we need to start extending ideas where we need to start extending ideas where we need to start extending ideas that we currently have to um become that we currently have to um become that we currently have to um become inclusive of the broader needs of the AI inclusive of the broader needs of the AI inclusive of the broader needs of the AI application vulnerability remediation application vulnerability remediation application vulnerability remediation response. And so if you have um access response. And so if you have um access response. And so if you have um access to the PDF of this deck, clicking on to the PDF of this deck, clicking on to the PDF of this deck, clicking on each one of those links will bring you each one of those links will bring you each one of those links will bring you down to a slide where you can see a list down to a slide where you can see a list down to a slide where you can see a list of resources that I've been using to um of resources that I've been using to um of resources that I've been using to um to kind of study and educate myself on to kind of study and educate myself on to kind of study and educate myself on what's kind of current state of those u what's kind of current state of those u what's kind of current state of those u in the industry. So we can look at what in the industry. So we can look at what in the industry. So we can look at what what does it take as these are what does it take as these are what does it take as these are converging to have a common universal converging to have a common universal converging to have a common universal framework. All right, next slide. Is that our Does that bring us to the Is that our Does that bring us to the Is that our Does that bring us to the end? Okay. Yes. To the end. Systems, you Systems, you Systems, you know, I'll just bring the the list of um know, I'll just bring the the list of um know, I'll just bring the the list of um industry reference links that you were industry reference links that you were industry reference links that you were just talking about there. So, here's a just talking about there. So, here's a just talking about there. So, here's a bunch of them that will be in the PDF bunch of them that will be in the PDF bunch of them that will be in the PDF for everybody to click through. Yeah. for everybody to click through. Yeah. for everybody to click through. Yeah. And I would imagine based off of the And I would imagine based off of the And I would imagine based off of the personal experience of you as an personal experience of you as an personal experience of you as an audience member listening to this, you audience member listening to this, you audience member listening to this, you have experience in one of these areas. have experience in one of these areas. have experience in one of these areas. And so what this does is it lets you And so what this does is it lets you And so what this does is it lets you begin to connect and explore to some of begin to connect and explore to some of begin to connect and explore to some of the other areas and and maybe even find the other areas and and maybe even find the other areas and and maybe even find people around your enterprise or the people around your enterprise or the people around your enterprise or the industry um that you can share your industry um that you can share your industry um that you can share your expertise with as they're trying to to expertise with as they're trying to to expertise with as they're trying to to seek to understand your area of seek to understand your area of seek to understand your area of expertise as well. Right. Okay. Well, that wraps us up. Right. Okay. Well, that wraps us up. Right. Okay. Well, that wraps us up. Thanks everyone for Thanks everyone for Thanks everyone for attending. Thanks Sarah as always for attending. Thanks Sarah as always for attending. Thanks Sarah as always for being a great partner. being a great partner. being a great partner. Yeah, I've really enjoyed putting this Yeah, I've really enjoyed putting this Yeah, I've really enjoyed putting this presentation together with you because presentation together with you because presentation together with you because you are kind of boots on the ground for you are kind of boots on the ground for you are kind of boots on the ground for um vulnerability remediation and it's um vulnerability remediation and it's um vulnerability remediation and it's it's it's been really great to partner it's it's been really great to partner it's it's been really great to partner with you thinking about how things are with you thinking about how things are with you thinking about how things are going to evolve and how we work to going to evolve and how we work to going to evolve and how we work to really advance that story together. So, really advance that story together. So, really advance that story together. So, thanks Lisa. thanks Lisa. thanks Lisa. Thanks Sarah. Okay. Yay.